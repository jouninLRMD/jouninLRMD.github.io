---
layout: presentation
title: "Elementos de Estadística con R"
main-class: 'presentaciones'
permalink: /SesionEsp01
tags:

introduction: 
image: <img src="../../SesionesEspeciales/images/logo.png" alt="UdeA" class="sticky">
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../SesionesEspeciales/_posts/", output_format = "all"  ) })
bibliography: "../referencias.bib"
csl: "../apa.csl"
link-citations: yes
---







Introducción
------------

La Estadística es una **herramienta** ampliamente utilizada en
diferentes disciplinas científicas, debido a su gran potencial para
**recolectar, analizar, interpretar, estimar y presentar** de forma
amigable, la información que se genera en las distintas áreas del
conocimiento, para así **poder argumentar y soportar de mejor manera las
investigaciones realizadas, y/o mejorar los resultados obtenidos en la
toma de decisiones**.

Adicionalmente, la estadística tiene como ventaja respecto a otras
áreas, que permite extraer información de **variables tanto númerida
como categórica** de la población de interés o de una muestra de la
misma, permitiendo al investigador establecer conclusiones acerca de la
misma población, o de alguno de los parámetros que la conforman. Y es
debido a ésto, que puede considerarse a la estadística como **uno de los
pilares fundamental** dentro de la investigación científica teórica y
aplicada.

En general, el análisis estadístico puede dividirse en dos partes:

-   La **Estadística descriptiva**, la cual se encarga de resumir la
    información suministrada mediante el empleo de tablas, gráficas y
    medidas numéricas, junto con el análisis de las mismas, para
    facilitar la interpretación y la presentación de la información.
-   La **Inferencia estadística**, la cual se encarga de la inferencias,
    modelamiento y predicción de la información, para facilitar la
    obtención de conclusiones y toma decisiones.

La estadística en políticas públicas
------------------------------------

**Las políticas públicas tienen como finalidad abordar problemas
sociales** que requieren de intervención desde el ámbito público, que
tienen como finalizad **gestionar planes, programas o proyectos que
permitan dar solución** de la mejor manera a dichos problemas.

Cada una las estrategias que buscan dar solución a los problemas
sociales, **requieren de un proceso de evaluación**, cuyo papel puede
ser igual o más importante que el objetivo mismo que se desea alcanzar.
Ésto debido a que, los proceso de evaluación **permiten analizar la
planificación** para retroalimentar el proceso de ejecución **a través
de la medición del impacto que generan las políticas** para la
comunidad. (Recchioni, [2016](#ref-Recchioni2016), p. 162)

**Es aquí donde el análisis estadísitico toma relevancia** dentro de las
políticas públicas, puesto que, ésta se emplea como una herramienta
indispensable en el análisis cualitativo o cuantitativo de información,
siendo dicho procedimiento, una parte escencial en el momento de diseñar
planes de evaluación de políticas.

Es debido a lo anterior que, **todo expertos en políticas públicas, debe
desarrollar una fuerte fundamentación en análisis de datos**, ya que
deben enfrentarse continuamente a problemas que requieren la tomar
decisiones, basandos en informes estadísticos descriptivos o
inferenciales, que tiene por finalidad apoyar la formulación,
implementación, gestión o evaluación de políticas públicas.

Pre-prosesamiento de datos
--------------------------

La limpieza o pre-procesamiento de los datos **es uno de los aspectos
más importantes cuando se desea trabajar con conjuntos de datos**, a tal
punto que muchos investigadores aseguran que en este procedimiento puede
emplearse regularmente desde el `$50\%$` hasta el `$80\%$` del tiempo
total de una investigación.

El objetivo principal de la limpieza de datos, es el **asegurar la
calidad de la información** que se usará en los análisis, además de
minimizar el riesgo en la toma de decisiones, en base a información
perdida, poco precisa, duplicada, contradictoria, errónea o incompleta,
ya qué ésta podría influir significativamente en los resultados
estadísticos y conclusiones.

Uno de los primeros procedimientos en la limpieza de datos, corresponde
en **transformar los datos sin procesar a datos tecnicamente
correctos**, y para ello es necesario corregir aquellos problemas que
pueden generarse en el momento de realizar la lectura de datos, que
pueden impedir o complicar la manipulación de la base de datos.

Dichos problemas están relacionados con, el hallazgo de carácteres
especiales, tipos o clases incorrectos para los conjuntos de datos,
datos faltantes, datos duplicados, entre otros.

Ena segunda fase, corresponde en **transformar los datos ténicamente
correcto a datos consistentes**, para lograr llevar los datos a una
**etapa en la que el conjunto de observaciones están listos para la
realización estadística descriptiva e inferencial**.

Este procedimiento consta en solucionar problemas relacionados con datos
faltantes o datos duplicados, que inflan la totalidad de la información
que se posea.

### Caso de estudio y variables

Como caso de estudio para esta sesión, se propone una base de datos
construida a partir del `$10\%$` de la información contenida en el Censo
de Edificaciones que posee el DANE para el periodo comprendido entre
2012-2018. Dicha base de datos puede ser descargada desde el siguiente
[Link](https://github.com/jouninLRMD/jouninlrmd.github.io/raw/master/Dataset/CesoEdificaciones2012-2018.csv){:target="\_blank"}.

Las variables contenidas en la base de datos anterior son:

-   **<tt>ANO\_CENSO</tt>:** Año al que corresponde la información
    recolectada en el Censo.
-   **<tt>TRIMESTRE</tt>:** Trimestre al que corresponde la información
    recolectada en el Censo.
-   **<tt>REGION</tt>:** Región de acuerdo con las áreas urbanas y
    metropolitanas en las cuales se realiza la publicación de la
    información.
    -   5 = Antioquia
    -   66 = Risaralda
    -   11 = Bogotá
    -   63 = Quindío
    -   76 = Valle
    -   54 = Norte de Santander
    -   50 = Meta
    -   8 = Atlántico
    -   41 = Huila
    -   68 = Santander
    -   13 = Bolívar
    -   52 = Nariño
    -   19 = Cauca
    -   73 = Tolima
    -   17 = Caldas
-   **<tt>OB\_FORMAL</tt>:** Define si la obra cuenta o no con licencia
    de construcción
    -   1 = Si
    -   2 = No
-   **<tt>ESTADO\_ACT</tt>:** El estado determina como se encontró la
    obra al momento del censo y se capta el código correspondiente.
    -   1 = Proceso
    -   2 = Paralizada con información completa
    -   3 = Culminada completa
    -   4 = Paralizada incompleta
    -   5 = Culminada con información incompleta
    -   6 = Demolida
-   **<tt>MOVIMIENTO</tt>:** El movimiento es el código de cambio de
    estado
    -   C = Continua
    -   I = Inactiva
    -   N = Nueva
    -   A = Ampliación cobertura
    -   R = Reinicia
    -   T = Culmina
    -   D = Demolida
-   **<tt>ESTRATO</tt>:** Clasificación dada por las empresas de
    servicios públicos. División numérica que caracteriza el entorno
    socio económico de un espacio geográfico y arquitectónico
    determinado
    -   1 = Bajo bajo
    -   2 = Bajo
    -   3 = Medio bajo
    -   4 = Medio
    -   5 = Medio Alto
    -   6 = Alto
-   **<tt>AREATOTZC</tt>:** Área total de zonas comunes cubiertas
    (incluido garaje y los depósitos o cuartos útiles como: portería,
    salones comunales, pasillos, etc.).
-   **<tt>AREAUNITGA</tt>:** Metros cuadrados de la unidad de garaje
    (cubiertos).
-   **<tt>PRECIOUNIG</tt>:** Valor de las unidades de garaje cubierto en
    miles de pesos.
-   **<tt>TIPOVALOR</tt>:** Tipo de valor de garaje cubierto
    -   1 = Real
    -   2 = Estimado
-   **<tt>MANO\_OBRAP</tt>:** Corresponde a la cantidad de mano de obra
    permanente generada en el período intercensal por tipo de mano de
    obra.
-   **<tt>MANO\_OBRAT</tt>:** Corresponde a la cantidad de mano de obra
    temporal generada en el período intercensal por tipo de mano de
    obra.
-   **<tt>AREA\_LOTE</tt>:** Corresponde al área del terreno donde se
    construye la obre o proyecto.
-   **<tt>AREAVENDIB</tt>:** Área total vendible (no incluye garaje y
    los depósitos o cuartos útiles).
-   **<tt>NRO\_PISOS</tt>:** Número de pisos del destino corresponde al
    número de pisos que conformarán cada destino que este en proceso de
    construcción.
-   **<tt>GRADOAVANC</tt>:** Grado de avance. Porcentaje de avance de
    obra del capítulo constructivo.
-   **<tt>PRECIOVTAX</tt>:** Precio de venta por M2 del destino, sin
    incluir garaje, en miles de pesos.
-   **<tt>AREAVENUNI</tt>:** Área total vendible por unidad (no incluye
    garaje y los depósitos o cuartos útiles).
-   **<tt>TIPOVIVI</tt>:** Tipo de vivienda hace referencia a si el
    destino es vivienda de interés social o no. Valor calculado
    -   1 = Vivienda de interés social
    -   2 = Vivienda diferente de VIS
-   **<tt>RANVIVI</tt>:** Rango de vivienda, valor calculado
    -   1 = SMLMV &lt; 50
    -   2 = 50 &lt; SMLMV ≤ 70
    -   3 = 70 &lt; SMLMV ≤ 100
    -   4 = 100 &lt; SMLMV ≤ 135
    -   5 = 135 &lt; SMLMV ≤ 350
    -   6 = SMLMV ≥ 350
-   **<tt>Destino2</tt>:** Identificación de la obra, según tipo o uso
    de la edificación, que se está construyendo.
    -   1 = Apartamento
    -   2 = Oficinas
    -   3 = Comercio
    -   4 = Casas
    -   5 = Bodegas
    -   6 = Destinos no comercializables (educación, hoteles, hospitales
        y centros de salud, administración pública y otros)

### Lectura de datos en <tt>R</tt>

Para realizar la lectura de datos en <tt>R</tt> es necesario conocer la
extensión que posee el archivo de interés, debido a que <tt>R</tt>
**posee diferentes librerías y funciones que permiten la lectura de
bases de datos**. En la siguiente tabla se resume el origen, la
extensión, la librería, y la función para cargar cada base de datos
dependiendo de su extensión.

<pre style="font-family: 'Open Sans',sans-serif; margin-bottom: -3rem; margin-top: -3rem; font-size: 120%;">
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Origen </th>
   <th style="text-align:left;"> Extensión </th>
   <th style="text-align:left;"> Librería </th>
   <th style="text-align:left;"> Función </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .txt </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> read.table() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .csv (comas) </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> read.csv() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .csv (punto y coma) </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> read.csv2() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Excel </td>
   <td style="text-align:left;"> .xls </td>
   <td style="text-align:left;"> readxl </td>
   <td style="text-align:left;"> read_xls() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Excel </td>
   <td style="text-align:left;"> .xlsx </td>
   <td style="text-align:left;"> readxl </td>
   <td style="text-align:left;"> read_xlsx() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SPSS </td>
   <td style="text-align:left;"> .sav </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> read.spss() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SAS </td>
   <td style="text-align:left;"> .sas7bdat </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> read.ssd() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> STATA </td>
   <td style="text-align:left;"> .dta </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> read.dta() </td>
  </tr>
</tbody>
</table>
</pre>

**Nota:** Las librerías con \* hacen referencia a funciones integradas
en <tt>R</tt>, y en consecuencia, no es necesario cargarlas antes de
usarlas.

A modo de ejemplo, suponga que se desea cargar una base de datos de
excel con extensión <tt>.xlsx</tt> **mediante la búsqueda del archivo en
el ordenador**. En este caso será necesario cargar la librería
<tt>readxl</tt> y posteriormente, cargar la base de datos mediante la
función <tt>read.xlsx()</tt> que sirve para cargar archivos con
extensión xlsx, y la función <tt>file.choose()</tt> que permite buscar
el archivo en el ordenador.

``` r
## Código de ejemplo NO CORRER
library(readxl)
datos <- read_xlsx(file.choose())
```

Por otro lado, suponga que deseamos cargar una base de datos de STATA
con extensión <tt>.dta</tt> **de forma automática**. En este caso será
necesario cargar la librería <tt>foreign</tt> y posteriormente, cargar
la base de datos mediante la función <tt>read.dta()</tt>, estableciendo
la localización en donde se encuentra el archivo en el ordenador.

``` r
## Código de ejemplo NO CORRER
library(foreign)
datos <- read.dta("C:/Users/user/Desktop/datos.dta")
```

Finalmente, suponga que se desea cargar una base de datos de Texto con
extensión <tt>.csv</tt>, la cual usa como separador de columnas el punto
y coma (;). En este caso será necesario descargar el archivo en una
locación temporal, mediante las funciones <tt>tempfile()</tt> y
<tt>download.file</tt>, y posteriormente, emplear la función
<tt>read.cvs2()</tt>, de la forma

``` r
## Código de ejemplo CORRER :D
temp <- tempfile(fileext = ".cvs")  # Crea archivo temporal
URL <- "https://raw.githubusercontent.com/jouninLRMD/jouninlrmd.github.io/master/Dataset/CesoEdificaciones2012-2018.csv"  # URL base de datos
download.file(URL, destfile = temp, mode = "wb")  # Descarga archivo en el archivo temporal creado
datos <- read.csv2(temp)
```

### Limpieza de datos (Datos sin procesar a datos ténicamente correctos)

#### Corrección encabezados en <tt>R</tt>

En muchas ocasiones, podemos enfrentarnos a bases de datos que **poseen
problemas en el nombre de los encabezados**, asociados caracteres
especiales tales como <tt>! " \# $ % & ’ ( ) \* + , - . / : ; &lt; =
&gt; ? @ \[ \] ^ \_ \` { | } ~</tt>, o abuso de letras mayúsculas en los
encabezados, entre otros.

Por ello **es necesario luego de cargar la base de datos, verificar si
tales problemas existen para poder corregirlos de alguna manera**. A
pesar de que en nuestro caso, no hay problemas de carácteres especiales
poseemos el problema del abuso de letras mayúsculas en el nombre de las
variables, lo cual podría ser tedioso en la programación, debido a que
<tt>R</tt> diferencia entre carácteres en mayúscula y minúscula.

Con el fin de darle solución a dicho problema, es posible emplear la
función <tt>clean\_names()</tt> de la librería <tt>janitor</tt>, con el
fin de

-   Analizar las mayúsculas y minúsculas y separadores a un formato
    consistente.
-   Maneja caracteres y espacios especiales.
-   Agrega números a nombres duplicados.
-   Convierte “%” en “percent” y “\#” en “number” para conservar el
    significado de la variable.

<!-- -->

``` r
# Se observa el nombre de las variables
names(datos)
```

     [1] "ANO_CENSO"  "TRIMESTRE"  "REGION"     "OB_FORMAL"  "AMPLIACION"
     [6] "ESTADO_ACT" "MOVIMIENTO" "ESTRATO"    "AREATOTZC"  "AREAUNITGA"
    [11] "PRECIOUNIG" "TIPOVALOR"  "MANO_OBRAP" "MANO_OBRAT" "AREA_LOTE" 
    [16] "AREAVENDIB" "NRO_PISOS"  "GRADOAVANC" "PRECIOVTAX" "AREAVENUNI"
    [21] "TIPOVIVI"   "RANVIVI"    "Destino2"  

``` r
# Elimina algunos carácteres especiales y abuso de mayúsculas
library(janitor)
datos <- clean_names(datos)

# Se observa el nombre de las variables
names(datos)
```

     [1] "ano_censo"  "trimestre"  "region"     "ob_formal"  "ampliacion"
     [6] "estado_act" "movimiento" "estrato"    "areatotzc"  "areaunitga"
    [11] "preciounig" "tipovalor"  "mano_obrap" "mano_obrat" "area_lote" 
    [16] "areavendib" "nro_pisos"  "gradoavanc" "preciovtax" "areavenuni"
    [21] "tipovivi"   "ranvivi"    "destino2"  

#### Corrección contenido de base de datos en <tt>R</tt>

Similar a los encabezados, puede ocurrir que se **encuentren problemas
en los valores contenidos dentro de cada variable**, a causa de
caracteres especiales o espacios, que puede generar que al transformar
las variables se creen categorías extras, o se pierdan datos numéricos.

Para dar solución a dicho problema, se pueden emplear en cojunto las
funciones <tt>lapply()</tt> y <tt>gsub()</tt> de la base de <tt>R</tt>,
para eliminar carácteres especiales y espacios dentro de la totalidad de
la base de datos. Posteriormente, se debe emplear la función
<tt>data.frame</tt> para que el conjunto de datos vuelva a tomar la
estructura de una base de datos. El código para realizar dicho
procedimiento se presenta a continuación.

``` r
# Elimina carácteres especiales y espacios dentro de la base de datos
datos <- lapply(datos, function(x) gsub("[[:punct:] [:blank:]]", "", x))
datos <- data.frame(datos, stringsAsFactors = F)
```

### Tipos de datos

En términos generales, los datos son cualquier pieza de información
recolectada del fenómeno que se pretende analizar, y que, dependiendo de
las características que posean, deben clasificarse dentro de una
determinada categoría.

-   **Cuantitativos**: Son datos que pueden ser medidos o cuantificados.
    Estos se subdividen en dos categorías:
    -   **Datos cuantitativos discretos**: Son aquellos datos que
        provienen de procesos que involucran conteos, y por tanto, solo
        pueden tomar valores enteros. Por ejemplo: **Edad de una
        persona, número de estudiantes que perdieron un curso, cantidad
        de profesores que dictan Estadística I**
    -   **Datos cuantitativos continuos**: Son aquellos datos que
        provienen de procesos que involucran mediciones, y por tanto,
        solo pueden tomar cualquier valor real dentro de un intervalo.
        Por ejemplo: **Temperatura de congelación del agua, Tiempo que
        dura una clase, Utilidad diaria de un negocio.**
-   **Cualitativos**: Son datos asociados a una cualidad o propiedad, y
    por tanto, no pueden representarse numéricamente, a pesar de poder
    caracterizarse alfanúmericamente. Por ejemplo: **Estrato
    socioeconómico, tipo de animales en una granja, nivel de
    satisfacción con el método planteado para dictar el curso.**
-   **Lógicos**: Son datos asociados a valores de lógica binaria,
    usualmente denotados como Verdadero y Falso, o Éxito y Fracaso. Por
    ejemplo: **Tipo de Sexo, cara de una moneda, probar si un artículo
    es defectuoso.**

#### Estructura de datos en <tt>R</tt>

**Para observar la estructura de los datos** en <tt>R</tt> puede
emplearse la función <tt>str()</tt>, la cual muestra la forma cómo está
siendo leída la información contenida en la base de datos por el
programa.

``` r
# Estructura de los datos
str(datos)
```

    'data.frame':   94432 obs. of  23 variables:
     $ ano_censo : chr  "2012" "2015" "2016" "2013" ...
     $ trimestre : chr  "2" "2" "2" "2" ...
     $ region    : chr  "41" "54" "76" "52" ...
     $ ob_formal : chr  "2" "2" "2" "1" ...
     $ ampliacion: chr  "2" "2" "2" "2" ...
     $ estado_act: chr  "1" "1" "1" "1" ...
     $ movimiento: chr  "N" "N" "N" "N" ...
     $ estrato   : chr  "2" "4" "4" "3" ...
     $ areatotzc : chr  "0" "0" "0" "590" ...
     $ areaunitga: chr  "0" "0" "0" "11" ...
     $ preciounig: chr  "0" "0" "0" "6000" ...
     $ tipovalor : chr  "0" "0" "0" "2" ...
     $ mano_obrap: chr  "0" "0" "0" "1" ...
     $ mano_obrat: chr  "3" "4" "3" "34" ...
     $ area_lote : chr  "84" "79" "85" "14548" ...
     $ areavendib: chr  "63" "155" "156" "7939" ...
     $ nro_pisos : chr  "1" "2" "2" "16" ...
     $ gradoavanc: chr  "30" "30" "50" "10" ...
     $ preciovtax: chr  "1200" "1160" "995" "1340" ...
     $ areavenuni: chr  "63" "155" "156" "62" ...
     $ tipovivi  : chr  "1" "2" "2" "2" ...
     $ ranvivi   : chr  "4" "5" "5" "5" ...
     $ destino2  : chr  "4" "4" "4" "1" ...

### Escala de medición

Las escalas o niveles de medición se utilizan para medir variables o
atributos que posea un conjunto de datos. A saber, las escalas de
medición se dividen en cuatro, **nominal, ordinal, intervalos y razón**.
Las dos primeras (nominal y ordinal) se conocen como escalas categóricas
usadas conmúnmente para variables cualitativas, mientras que las dos
últimas (intervalo y razón) se conocen como escalas numéricas, usadas
comúnmente para variables cuantitativas.

-   **Nominal**: Son aquellos factores que establecen etiquetas o
    categorías a los datos, sin estar sujetos a un orden específico. Por
    ejemplo: **Partido político, Comuna de residencia**
-   **Ordinal**: Son aquellos factores que establecen etiquetas o
    categorías a los datos, junto a una estructura jerárquica. Por
    ejemplo: **Nivel de una enfermedad, Grado de escolaridad**
-   **Intervalo**: Son aquellas mediciones cuantitativas que establecen
    la distancia entre una medida y otra, en términos de una unidad de
    medición fija, donde **el cero se selecciona de forma arbitraria y
    no indica ausencia del tributo**, ni indica conceptos como
    ‘ninguno’, ‘vacío’ o ‘nada’. Por ejemplo: **Unidades de medida en
    centígrados o Fahrenheit**
-   **Razón**: Son aquellas mediciones cuantitativas que establece la
    distancia exacta de una categoría debido a que **el cero es
    absoluto, no es arbritario, e indica ausencia del atributo**. Por
    ejemplo **Índice de masa corporal, Salario**

### Coerción de datos en <tt>R</tt>

Muchas veces cuando tenemos una variable, puede que esta no tenga
almacenados los datos bajo el tipo que queremos tenerlo realmente, por
ello, será necesario transformar (coercionar) cada variable, que permita
ajustar la variable a tipo deseado. En <tt>R</tt> existen funciones que
permiten redefinir una variable, para transformarlo al tipo que
necesitamos. Estás funciones son

-   **<tt>as.numeric()</tt>:** Convierte una variable a tipo numérico
    (double).
-   **<tt>as.logical()</tt>:** Convierte una variable a tipo lógico.
-   **<tt>as.integer()</tt>:** Convierte una variable a tipo entero.
-   **<tt>factor()</tt>:** Convierte una variable a tipo factor
    asumiendo o no un orden o jerarquía entre los niveles.
-   **<tt>as.character()</tt>:** Convierte una variable a tipo carácter
    (character).
-   **<tt>factor()</tt>:** Convierte una variable a tipo factor
    asumiendo o no un orden o jerarquía entre los niveles.

En nuestro caso, tenemos que todas las variables aparecen como si fuesen
variables de tipo carácter, debido al procedimiento de la corrección que
se hizo para eliminar carácteres especiales y espacios dentro de la base
de datos. En consecuencia, debemos transformar cada variable dependiendo
de su estructura y escala de medición.

En sí, tenemos que en primer lugar, las variables <tt>ANO\_CENSO,
TRIMESTRE, ESTRATO y RANVIVI</tt> son **variables cualitativas
ordinales** y por ello deben se transformadas a variables de tipo factor
ordinal. En segundo lugar, las variables <tt>REGION, OB\_FORMAL,
ESTADO\_ACT, MOVIMIENTO, TIPOVALOR, TIPOVIVI y Destino2</tt> son
**variables cualitativas nominales** y deben ser transformadas a
variables de tipo factor. Finalmente, las demás son **variables
cuantitativas de razón** que pueden trabajarse como variables de tipo
numéricas o enteros.

Para llevar a cabo la transformación, podemos emplear la función
<tt>factor()</tt> para realizar el cambio de las **variables
cualitativas ordinales**, la función <tt>factor()</tt> para realizar el
cambio de las **variables cualitativas nominales** y la función
<tt>as.numeric()</tt> para realizar el cambio de las variables a tipo
numérica.

``` r
# Coerción de variable por variable
datos$ano_censo <- factor(datos$ano_censo, ordered = T)
datos$trimestre <- factor(datos$trimestre, ordered = T)
datos$region <- factor(datos$region, levels = c(5, 8, 11, 13, 17, 19, 41, 50, 
    52, 54, 63, 66, 68, 73, 76), labels = c("Antioquia", "Atlántico", "Bogotá", 
    "Bolívar", "Caldas", "Cauca", "Huila", "Meta", "Nariño", "Norte de Santander", 
    "Quindío", "Risaralda", "Santander", "Tolima", "Valle"))
datos$ob_formal <- factor(datos$ob_formal, level = c(1, 2), labels = c("Sí", 
    "No"))
datos$estado_act <- factor(datos$estado_act, level = c(1, 2, 3, 4, 5, 6), labels = c("Proceso", 
    "ParalizadaInfC", "CulminadaInfC", "ParalizadaInfI", "CulminadaInfI", "Demolida"))
datos$movimiento <- factor(datos$movimiento, levels = c("A", "C", "I", "N", 
    "R", "T"), labels = c("Ampliación", "Continua", "Inactiva", "Nueva", "Reinicia", 
    "Culmina"))
datos$estrato <- factor(datos$estrato, ordered = T)
datos$areatotzc <- as.numeric(datos$areatotzc)
datos$areaunitga <- as.numeric(datos$areaunitga)
datos$preciounig <- as.numeric(datos$preciounig)
datos$tipovalor <- factor(datos$tipovalor, level = c(0, 1, 2), labels = c("No responde", 
    "Real", "Estimado"))
datos$mano_obrap <- as.numeric(datos$mano_obrap)
datos$mano_obrat <- as.numeric(datos$mano_obrat)
datos$area_lote <- as.numeric(datos$area_lote)
datos$areavendib <- as.numeric(datos$areavendib)
datos$nro_pisos <- as.numeric(datos$nro_pisos)
datos$gradoavanc <- as.numeric(datos$gradoavanc)
datos$preciovtax <- as.numeric(datos$preciovtax)
datos$areavenuni <- as.numeric(datos$areavenuni)
datos$tipovivi <- factor(datos$tipovivi, level = c(1, 2), labels = c("Social", 
    "No Social"))
datos$ranvivi <- factor(datos$ranvivi, ordered = T)
datos$destino2 <- factor(datos$destino2, level = c(1, 2, 3, 4, 5, 6), labels = c("Apartamento", 
    "Oficina", "Comercio", "Casas", "Bodega", "Otros"))
# Estructura de los datos
str(datos)
```

    'data.frame':   94432 obs. of  23 variables:
     $ ano_censo : Ord.factor w/ 7 levels "2012"<"2013"<..: 1 4 5 2 7 5 5 1 3 6 ...
     $ trimestre : Ord.factor w/ 4 levels "1"<"2"<"3"<"4": 2 2 2 2 1 4 1 4 1 1 ...
     $ region    : Factor w/ 15 levels "Antioquia","Atlántico",..: 7 10 15 9 4 11 3 3 3 8 ...
     $ ob_formal : Factor w/ 2 levels "Sí","No": 2 2 2 1 1 1 2 1 1 2 ...
     $ ampliacion: chr  "2" "2" "2" "2" ...
     $ estado_act: Factor w/ 6 levels "Proceso","ParalizadaInfC",..: 1 1 1 1 1 1 1 1 1 1 ...
     $ movimiento: Factor w/ 6 levels "Ampliación","Continua",..: 4 4 4 4 4 4 4 4 4 4 ...
     $ estrato   : Ord.factor w/ 6 levels "1"<"2"<"3"<"4"<..: 2 4 4 3 4 3 4 3 3 1 ...
     $ areatotzc : num  0 0 0 590 1820 1990 0 390 0 0 ...
     $ areaunitga: num  0 0 0 11 12 11 0 0 0 0 ...
     $ preciounig: num  0 0 0 6000 20000 16000 0 0 0 0 ...
     $ tipovalor : Factor w/ 3 levels "No responde",..: 1 1 1 3 3 3 1 1 1 1 ...
     $ mano_obrap: num  0 0 0 1 1 3 0 10 2 0 ...
     $ mano_obrat: num  3 4 3 34 25 20 3 70 36 2 ...
     $ area_lote : num  84 79 85 14548 1661 ...
     $ areavendib: num  63 155 156 7939 13581 ...
     $ nro_pisos : num  1 2 2 16 14 10 2 6 3 1 ...
     $ gradoavanc: num  30 30 50 10 2 15 50 60 10 80 ...
     $ preciovtax: num  1200 1160 995 1340 4150 1450 1600 1200 2550 580 ...
     $ areavenuni: num  63 155 156 62 206 66 150 49 85 68 ...
     $ tipovivi  : Factor w/ 2 levels "Social","No Social": 1 2 2 2 2 2 2 1 2 1 ...
     $ ranvivi   : Ord.factor w/ 6 levels "1"<"2"<"3"<"4"<..: 4 5 5 5 6 5 5 4 6 2 ...
     $ destino2  : Factor w/ 6 levels "Apartamento",..: 4 4 4 1 1 1 4 1 4 4 ...

### Limpieza de datos (Datos ténicamente correctos a datos consistentes)

#### Remover filas o columnas vacías en <tt>R</tt>

Este procedimiento, **permite buscar y eliminar aquellas filas o
columnas que se encuentran totalmente vacías** y que pueden de alguna
manera inflar la totalidad de información que se posee en la base de
datos.

Para ello se emplea la función <tt>remove\_empty()</tt> de la librería
<tt>janitor</tt>.

``` r
# Muestra dimensión de filas y columnas antes de la eliminación
dim(datos)
```

    [1] 94432    23

``` r
# Elimina filas y columnas que poseen solo valores NA
datos <- remove_empty(datos, which = c("rows", "cols"))
# Muestra dimensión de filas y columnas despues de la eliminación
dim(datos)
```

    [1] 94281    23

#### Remover filas duplicadas en <tt>R</tt>

Este procedimiento **se emplea preferiblemente cuando se posee una
variable de identificación única**, tal como cédula o nit, que permita
comparar cada fila y eliminar solo aquellas que realmente se encuentren
duplicadas.

Para eliminar las filas que se encuentren duplicadas, es posible emplear
la función <tt>distinct()</tt> de la librería <tt>dplyr</tt>, de la
forma.

``` r
library(dplyr)
# Muestra dimensión de filas y columnas antes de la eliminación
dim(datos)
```

    [1] 94281    23

``` r
# Elimina filas que poseen registros duplicados
datos <- distinct(datos)
# Muestra dimensión de filas y columnas despues de la eliminación
dim(datos)
```

    [1] 86148    23

#### Detección de datos faltantes en <tt>R</tt>

La detección de datos faltantes radica en localizar para cada variable,
si se encuentran casillas vacías, valores especiales, tales como
<code style="color: #ff628c!important">Na, NaN</code> o
<code style="color: #ff628c!important">NULL</code>.

-   **<code style="color: #ff628c!important">NA</code> (Not
    Available):** Es un carácter especial para indicar valores perdidos.
    Éstos pueden ser detectados en <tt>R</tt> mediante la función
    <tt>is.na()</tt>.
-   **<code style="color: #ff628c!important">NaN</code> (Not a
    number):** Es un carácter especial para datos de clase numérica,
    para indicar un valor asociado a un cálculo cuyo resultado es
    desconocido, el cual seguramente no es un número. Este puede
    obtenerse mediante operaciones tales como `$0/0$`, `$Inf/Inf$`,
    `$Inf-Inf$`. Éstos pueden ser detectados en <tt>R</tt> mediante la
    función <tt>is.nan()</tt>, aunque también son detectados por la
    función <tt>is.na()</tt>.
-   **<code style="color: #ff628c!important">NULL</code>:** Es un
    carácter especial para indicar valores indefinidos o indicar la no
    existencia de valor dentro de la base de datos o de una entrada de
    la misma. Éstos pueden ser detectados en <tt>R</tt> mediante la
    función <tt>is.null()</tt>.

Para detectar aquellas filas que se encuentren faltantes dentro de una
base de datos, podemos usar una combinación entre las funciones
<tt>apply()</tt>, <tt>which()</tt>, tal como se muestra en la siguiente
linea de código, adicionando las funciones <tt>is.na()</tt> e
<tt>is.null()</tt>, dentro de la función <tt>which()</tt>.

``` r
## Detectar NA, NaN y NULL dentro de la base de datos
faltantes <- apply(X = datos, MARGIN = 2, FUN = function(x) which(is.na(x) | 
    is.null(x) | x == "Na" | x == "NA" | x == "NaN"))  # se pueden agregar más caracteres
faltantes
```

    $ano_censo
    integer(0)

    $trimestre
    integer(0)

    $region
    integer(0)

    $ob_formal
    integer(0)

    $ampliacion
    integer(0)

    $estado_act
    integer(0)

    $movimiento
    [1] 69018

    $estrato
    integer(0)

    $areatotzc
    [1] 15450 26675 48622 85119

    $areaunitga
    integer(0)

    $preciounig
    [1] 46372

    $tipovalor
    integer(0)

    $mano_obrap
    [1] 36956

    $mano_obrat
    [1] 49959

    $area_lote
    integer(0)

    $areavendib
    integer(0)

    $nro_pisos
    [1] 51050

    $gradoavanc
    integer(0)

    $preciovtax
    integer(0)

    $areavenuni
    integer(0)

    $tipovivi
    integer(0)

    $ranvivi
    integer(0)

    $destino2
    integer(0)

### Exportar datos en <tt>R</tt>

Una vez corregida la base de datos, es posible exportar la información
para emplearla posteriormente en <tt>R</tt> o en otros programas.
<tt>R</tt> **posee diferentes librerías y funciones que permiten
exportar bases de datos** dependiendo de la extensión de interés. En la
siguiente tabla se resume el origen, la extensión, la librería, y la
función para cargar cada base de datos dependiendo de su extensión.

<pre style="font-family: 'Open Sans',sans-serif; margin-bottom: -3rem; margin-top: -3rem; font-size: 120%;">
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Origen </th>
   <th style="text-align:left;"> Extensión </th>
   <th style="text-align:left;"> Librería </th>
   <th style="text-align:left;"> Función </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .txt </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> write.table() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .csv (comas) </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> write.csv() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Texto </td>
   <td style="text-align:left;"> .csv (punto y coma) </td>
   <td style="text-align:left;"> utils* </td>
   <td style="text-align:left;"> write.csv2() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Excel </td>
   <td style="text-align:left;"> .xlsx </td>
   <td style="text-align:left;"> openxlsx </td>
   <td style="text-align:left;"> write.xlsx() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SPSS </td>
   <td style="text-align:left;"> .sav </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> write.foreign() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SAS </td>
   <td style="text-align:left;"> .sas7bdat </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> write.foreign() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> STATA </td>
   <td style="text-align:left;"> .dta </td>
   <td style="text-align:left;"> foreign </td>
   <td style="text-align:left;"> write.foreign() </td>
  </tr>
</tbody>
</table>
</pre>

Para mostrar el empleo de estas funciones, suponga que queremos exportar
la base de datos en extensión, <tt>.xlsx</tt>. Para ello se emplea
entonces la función <tt>write.xlsx()</tt> de la librería
<tt>openxlsx</tt>.

``` r
library(openxlsx)
## Se escribe el nombre del archivo, junto a la extensión de donde se quiera
## guardar
write.xlsx(x = datos, "C:/Users/user/Desktop/datos.xlsx")
```

Estadística descriptiva
-----------------------

En general, la importancia del análisis estadístico radica en la
**resolución de problemas vinculados con datos**, siendo la variabilidad
de los mísmos, quién guiará la importancia del empleo de diferentes
ténicas para el manejo de la información. Desde este punto de vista, se
explica en esta sección el método de implementación en <tt>R</tt> de
resúmenes de información, resumenes tabulares y gráficos para la
presentación de información de forma adecuada, para facilitar la toma de
decisiones.

Un aspecto importante a tener en cuenta al realizar análisis
estadísticos, es señalado por Esquivel ([2016](#ref-Esquivel2016), p.
29), el cual menciona que dentro de un análisis con información
estadística, se debe tener en cuenta las siguientes etapas:

1.  **Leer entre los datos**: que consiste en llevar a cabo una lectura
    literal de la información, sin interpretar su contenido).
2.  **Leer dentro de los datos**: implica no solamente interpretar los
    datos sino integrarlos dentro del contexto.
3.  **Leer más allá de los datos**: significa tomar los datos como
    referente para identificar patrones que transciendan el grupo de
    datos observado, ya sea mediante la interpolación o extrapolación de
    resultados.
4.  **Leer detrás de los datos**: consiste en llevar a cabo un análisis
    crítico de la información que se estudia, esto implica analizar
    integralmente el problema, desde su origen, el tipo de dato que se
    utiliza, su validez y fiabilidad para analizar el problema y la
    posibilidad de generalizar los hallazgos.

### Resumen numéricos (Variables cuantitativas)

Una parte importante en la estadística descriptiva, son **las medidas
estadísticas que tienen por objetivo resumir la información contenida en
un conjunto de datos, en pocos valores númericos que representan
diferentes características**. Estas medidas estadísticas nos darán
información sobre la situación, dispersión, forma, asociación que posee
un conjunto de datos de manera que sea posible captar rápidamente la
estructura de los mismos.

Las medidas estadísticas que se explicarán en esta sesión podrán ser
econtradas en la [Clase
01](../../EstadisticaI/EstIClase01.html#medidas-estadísticas){:target="\_blank“}
y [Clase
02](../../EstadisticaI/EstIClase02.html#medidas-estadísticas){:target=”\_blank"}
del curso de Estadística I.

**Una alternativa para presentar la información que aportan las medidas
estadísticas**, sin tener que realizar el cálculo de cada una de forma
individual, **es mediante el empleo de resúmenes numéricos**, los cuales
permiten presentar de forma simple, ordenada y simultanea las diferentes
medidas que representan el comportamiento de un conjunto de datos.

#### Resumen numérico individual

Entre las diferentes funciones que permiten realizar resúmenes numéricos
en <tt>R</tt>, se destaca la función <tt>describe()</tt> de la librería
<tt>psych</tt>, que presentan diferentes medidas estadísticas para
variables tipo numéricas.

Suponga que se desea realizar un resumen numérico de la variable
<tt>areavenuni</tt> (Área total vendible por unidad). En este caso
podríamos emplear la función <tt>describe()</tt> especificando las
variables que se desean calcular, de la forma.

``` r
library(psych)

# resumen numérico mediante librería psych
describe(datos$areavenuni, ranges = TRUE, trim = 0.1, type = 3, quant = c(0.25, 
    0.75), IQR = TRUE)
```

      vars     n   mean     sd median trimmed   mad min  max range skew
    1    1 86148 124.81 100.08     92  106.83 54.86  11 3792  3781 4.15
      kurtosis   se IQR Q0.25 Q0.75
    1    51.58 0.34  88    62   150

#### Resumen numérico por grupos

También es posible realizar resúmenes numérico por grupos, en donde, se
busca tomar una variable cuantitativa, y discriminarla por una variable
cualitativa. Para ello, es posible emplear la función
<tt>describeBy</tt> de la librería <tt>psych</tt>, la cual permite
establecer una variable de tipo **numerica**, y agrupar los resultados
por los niveles de una variable tipo **factor**.

Suponga que se desea realizar un resumen numérico de la variable
<tt>areavenuni</tt> (Área total vendible por unidad), discriminando por
la variable estrato (estrato socioeconómico de un espacio geográfico).
En este caso podríamos emplear la función <tt>describeBy()</tt>
especificando las variables que se desean calcular, de la forma.

``` r
# resumen numérico por grupos mediante librería psych
describeBy(x = datos$areavenuni, group = datos$estrato, ranges = TRUE, trim = 0.1, 
    type = 3, quant = c(0.25, 0.75), IQR = TRUE)
```


     Descriptive statistics by group 
    group: 1
      vars     n  mean    sd median trimmed   mad min max range skew kurtosis
    1    1 11171 87.75 52.11     72   79.03 31.13  11 780   769 2.43    10.96
        se IQR Q0.25 Q0.75
    1 0.49  50    55   105
    -------------------------------------------------------- 
    group: 2
      vars     n   mean    sd median trimmed   mad min  max range skew
    1    1 25852 106.79 69.75     81   95.42 47.44  15 1350  1335 2.14
      kurtosis   se IQR Q0.25 Q0.75
    1     10.8 0.43  82    58   140
    -------------------------------------------------------- 
    group: 3
      vars     n   mean    sd median trimmed   mad min  max range skew
    1    1 28138 115.84 80.18     85   101.5 45.96  12 1160  1148 2.02
      kurtosis   se IQR Q0.25 Q0.75
    1     6.64 0.48  83    61   144
    -------------------------------------------------------- 
    group: 4
      vars     n   mean    sd median trimmed   mad min max range skew kurtosis
    1    1 12452 134.54 78.46    115  122.55 57.82  18 800   782 2.14     7.78
       se IQR Q0.25 Q0.75
    1 0.7  81    81   162
    -------------------------------------------------------- 
    group: 5
      vars    n   mean     sd median trimmed   mad min  max range skew
    1    1 5011 187.58 133.89    146  165.24 83.03  21 1400  1379 2.33
      kurtosis   se IQR Q0.25 Q0.75
    1     8.42 1.89 131   100   231
    -------------------------------------------------------- 
    group: 6
      vars    n   mean     sd median trimmed    mad min  max range skew
    1    1 3524 322.35 222.87    290  293.41 184.58  31 3792  3761 3.34
      kurtosis   se    IQR Q0.25  Q0.75
    1    28.14 3.75 248.25   162 410.25

### Resumen tabular (Variables cualitativas)

Una forma convencional de presentar resúmenes de variables cualitativas,
es mediante la construcción de tablas de frecuencias, las cuales
permiten presentar de **forma individual** (una vía) algunas de las
características que poseen las variables cualitativas, o de **forma
conjunta** (dos vías) algunas de las características que comparten
dichas variables.

#### Tabla de frecuencias absolutas

Para presentar de forma individual o grupal las características de las
variables, puede ser empleada la función <tt>table()</tt> de la base de
<tt>R</tt>, la cual agrega la información presentada en de las variables
de una forma simple, mediante una tabla que presenta el número
**(frecuencia absoluta)** de observaciones que pertenecen a una
categoría. Se aconseja que los datos usados dentro de la función
<tt>table()</tt> sean de tipo *factor*.

Las tablas de frecuencia pueden ser construida en una o dos vías, es
decir, las tablas pueden presentar la frecuencia absoluta de una sola
variable, o presentar la frecuencia absoluta del cruce entre dos
variables.

Para ilustrar su empleo, suponga que se desea observar el estado en el
cual se encontraron las obras al momento de realizar el censo
(<tt>estado\_act</tt>). Al ser una sola variable, la función
<tt>table()</tt> se emplea de la siguiente forma

``` r
# tabla de frecuencias absolutas una vía
Tunavia <- table(datos$estado_act)
Tunavia
```


           Proceso ParalizadaInfC  CulminadaInfC ParalizadaInfI  CulminadaInfI 
             78355           4196           1251           2324             21 
          Demolida 
                 1 

Ahora suponga, que se desea observar el cruce que hay entre el año en
que se realizó el censo (<tt>ano\_censo</tt>) y el estado actual en el
cual se encontraron las obras al momento de realizar el censo
(<tt>estado\_act</tt>). En éste caso, al ser dos variables, la función
<tt>table()</tt> debe emplearse de la siguiente manera

``` r
# tabla de frecuencias absolutas doble vía
Tdosvias <- table(datos$ano_censo, datos$estado_act)
Tdosvias
```

          
           Proceso ParalizadaInfC CulminadaInfC ParalizadaInfI CulminadaInfI
      2012    9025            114            14            524             0
      2013   12637            108             3            385             3
      2014   12551             81            18            251             0
      2015   12612            102            14            274             1
      2016   10577            176             5            289             0
      2017   11472            793           163            321             2
      2018    9481           2822          1034            280            15
          
           Demolida
      2012        0
      2013        0
      2014        0
      2015        0
      2016        0
      2017        1
      2018        0

#### Tabla de frecuencias absolutas

Una alternativa para presentar la información contenida dentro de las
variables cualitativas, es mediante la presentación de tablas de
frecuencias relativas, las cuales muestran **el valor porcentual al que
equivale una categoría específica**.

Para la realización de tablas de frecuencias relativas, se emplea la
función <tt>prop.table(tabla)</tt> de base de <tt>R</tt>, en donde
<tt>tabla</tt> hace referencia a la tabla de frecuencias absolutas
creada en la subsección anterior.

Para ilustrar su empleo, suponga que se desea observar el valor
porcentual para los diferentes estados en el cual se encontraron las
obras al momento de realizar el censo (<tt>estado\_act</tt>). Al ser una
sola variable, la función <tt>prop.table()</tt> se emplea de la
siguiente forma

``` r
# tabla de frecuencias relativas una vía
Punavia <- prop.table(Tunavia)
Punavia
```


           Proceso ParalizadaInfC  CulminadaInfC ParalizadaInfI  CulminadaInfI 
     0.90953939732  0.04870687654  0.01452152110  0.02697683057  0.00024376654 
          Demolida 
     0.00001160793 

En el mismo hílo, suponga que se desea observar en valores porcentuales,
el cruce que hay entre el año en que se realizó el censo
(<tt>ano\_censo</tt>) y el estado actual en el cual se encontraron las
obras al momento de realizar el censo (<tt>estado\_act</tt>). En éste
caso, al ser dos variables, la función <tt>prop.table()</tt> debe
emplearse de la siguiente manera

``` r
# tabla de frecuencias relativas doble vía
Pdosvias <- prop.table(Tdosvias)
Pdosvias
```

          
                 Proceso ParalizadaInfC CulminadaInfC ParalizadaInfI
      2012 0.10476157311  0.00132330408 0.00016251103  0.00608255560
      2013 0.14668941821  0.00125365650 0.00003482379  0.00446905326
      2014 0.14569113618  0.00094024237 0.00020894275  0.00291359057
      2015 0.14639921995  0.00118400891 0.00016251103  0.00318057297
      2016 0.12277708130  0.00204299577 0.00005803965  0.00335469193
      2017 0.13316617913  0.00920508892 0.00189209268  0.00372614570
      2018 0.11005478943  0.03275757998 0.01200260018  0.00325022055
          
           CulminadaInfI      Demolida
      2012 0.00000000000 0.00000000000
      2013 0.00003482379 0.00000000000
      2014 0.00000000000 0.00000000000
      2015 0.00001160793 0.00000000000
      2016 0.00000000000 0.00000000000
      2017 0.00002321586 0.00001160793
      2018 0.00017411896 0.00000000000

### Análisis gráfico

Otro aspecto importante del análisis descriptivo, es el que se realiza
mediante análisis gráfico. **El análisis gráfico es una forma de
simplificar lo tedioso y complejo de un conjunto de observaciones**,
además de ser una forma más accesible de presentación de la información
cuando se tienen muchas variables, puesto que permiten mostrar el
comportamiento de los datos presentados, y hacer juicios respecto a su
tendencia central, variabilidad, formas, patrones, tendencias, etc.

El análisis gráfico, puede ser dividido en

-   Gráficos para variables cuantitativa
-   Gráficos para variables cualitativas
-   Gráficos para cruces entre variables cuantitativas y cualitativas

En la siguiente tabla se hace un resumen de qué gráficos pueden ser
apropiados para usar en cada uno de los casos

<pre style="font-family: 'Open Sans',sans-serif; margin-bottom: -3rem; margin-top: -3rem; font-size: 120%;"><table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;"><thead>
  <tr>
   <th style="text-align:left;"> Categoría</th>
   <th style="text-align:left; text-align: center" colspan="3"> Tipo de Gráficos </th>
  </tr>
 </thead>
<tbody>
<tr>
<td style="text-align:left;"> <a href="http://jouninlrmd.github.io/SesionEsp01#una-variable-cuantitativa" style="
    color: #ffffff;
"><b><u>Una Cuantitativa</u></b></a></td>
<td style="text-align:left;">Gráfico de caja y bigotes</td>
<td style="text-align:left;">Histograma</td>
<td style="text-align:left;">Densidad</td>
</tr>
<tr>
<td style="text-align:left;"> <a href="https://jouninlrmd.github.io/SesionEsp01#dos-variables-cuantitativas" style="
    color: #ffffff;
"><b><u>Dos Cuantitativas</u></b></a></td>
<td style="text-align:left;">Diagrama de dispersión</td>
<td style="text-align:left;"></td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;"> <a href="https://jouninlrmd.github.io/SesionEsp01#más-de-dos-variables-cuantitativas" style="
    color: #ffffff;
"><b><u>Más de Dos Cuantitativas</u></b></a></td>
<td style="text-align:left;">Matriz de dispersión</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;"> <a href="https://jouninlrmd.github.io/SesionEsp01#una-variable-cualitativa" style="
    color: #ffffff;
"><b><u>Una Cualitativa</u></b></a></td>
<td style="text-align:left;">Gráfico de barras
</td>
<td style="text-align:left;">Gráfico de pareto
</td>
<td style="text-align:left;">Gráfico de pastel
</td>
</tr>
<tr>
<td style="text-align:left;"> <a href="https://jouninlrmd.github.io/SesionEsp01#dos-variables-cualitativas" style="
    color: #ffffff;
"><b><u>Dos Cualitativas</u></b></a></td>
<td style="text-align:left;">Gráfico de barras</td>
<td style="text-align:left;">Gráfico de balón</td>
<td style="text-align:left;"></td>
</tr>
<tr>
<td style="text-align:left;"> <a href="https://jouninlrmd.github.io/SesionEsp01#cruce-entre-variables-cualitativas-y-cuantitativas" style="
    color: #ffffff;
"><b><u>Cualitativa - Cuantitativa</u></b></a></td>
<td style="text-align:left;">Gráfico de caja y bigotes</td>
<td style="text-align:left;">Gráfico de medias</td>
<td style="text-align:left;"></td>
</tr>
</tbody>
</table></pre>

#### Una variable Cuantitativa

**Gráfico de caja y bigotes**<br><br> Este gráfico sirve para presentar
de forma visual, datos numéricos a través de sus cuartiles, además de
presentar otras **características importantes, tales como el valor de
los cuartiles, dispersión, simetría y datos potencialmente atípicos**.

<h4 align="center">
Representación de un Gráfico de Caja y Bigotes
</h4>

![](../EstadisticaI/images/BoxPlot.jpg)

Este gráfico puede ser realizado mediante la función <tt>boxplot()</tt>
de la librería <tt>graphics</tt> de la base del <tt>R</tt>.

Suponga que se desea presentar de forma visual, el comportamiento de la
variable que corresponde al grado de avance de la obra en contrucción
(<tt>gradoavanc</tt>) a partir de el comportamiento de los cuartiles.
Para ello, podemos emplear la función <tt>boxplot()</tt> de la forma

``` r
# Construcción de gráfico de caja y bigotes
boxplot(datos$gradoavanc, horizontal = T, xlab = "Porcentaje de avance (%)", 
    main = "Boxplot del Grado de Avance de la Obra", col = "lightblue")
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-23-1.png)

**Histograma**<br><br> Este gráfico muestra la distribución de
frecuencia o densidades del grupo de observaciones, **brinda información
sobre el valor más probables, la dispersión, la asimetría y valores
extremos**. Adicionalmente, tiene la ventaja de que su interpretación es
muy intuitiva y por tanto es de los gráficos más preferidos para resumir
información. Este gráfico puede ser realizado mediante la función
<tt>hist()</tt> de la librería <tt>graphics</tt> de la base del
<tt>R</tt>.

Suponga que se desea presentar mediante un histograma, el comportamiento
de la variable que corresponde al precio de venta por `$m^2$` del
inmueble (<tt>preciovtax</tt>). Para ello, podemos emplear la función
<tt>hist()</tt> de la forma

``` r
## Construcción de histograma
hist(datos$preciovtax, main = "Histograma del Precio de venta por M2", xlab = "Precio (en miles de pesos)", 
    col = 8)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-24-1.png)

**Densidad**<br><br> Este gráfico funciona similar al histograma de
densidades, con la diferencia de que en lugar de mostrar la distribución
mediante clases (barras), éste muestra el comportamiento de la
distribución de las observaciones mediante una curva. Dicha curva,
**brinda mayor información que el histograma respecto al valor promedio,
dispersión y asimetría**. Este gráfico puede ser realizado mediante la
combinación de las funciones <tt>plot()</tt> y <tt>density()</tt>, de la
forma <tt>plot(density())</tt>, siendo <tt>plot()</tt> y
<tt>density()</tt> funciones de las librerías <tt>graphics</tt> y
<tt>stats</tt> de la base de <tt>R</tt>.

Adicionalmente se presenta la función <tt>polygon</tt> de la librería
<tt>graphics</tt> de la base de <tt>R</tt>, la cual sirve para generar
formas, o en este caso, darle color a la densidad.

Suponga que se desea presentar la densidad, de la variable que
corresponde al área total vendible por unidad (<tt>areavenuni</tt>).
Para ello, podemos emplear la función <tt>hist()</tt> de la forma

``` r
## Construcción de la densidad
plot(density(datos$areavenuni, na.rm = T), main = "Gráfico de Densidad para Area Total Vendible", 
    xlab = "Área Total Vendible", lwd = 2)
# Colorea la densidad
polygon(density(datos$areavenuni, na.rm = T), col = 3)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-25-1.png)

#### Dos variables Cuantitativas

**Gráfico de dispersión**<br><br> Este gráfico se emplea para hacer
cruces entre dos variables cuantitativas, y **sirve para ver tendencias
y relaciones entre dos variables cuantitativas, además de permitir
apreciar donde se centra el total de observaciones, y detección de datos
atípicos** dados dos atributos cuantitativos. Este gráfico puede ser
realizado mediante la función <tt>plot()</tt> de la librería
<tt>graphics</tt> de la base del <tt>R</tt>.

Para entender la forma en que se aplica un diagrama de dispersión,
suponga que se quiere observar, si éxiste alguna relación entre el área
del lote donde se construye la obra o proyecto (<tt>area\_lote</tt>) y
el precio de venta por `$m^2$` (<tt>preciovtax</tt>). Para ello, podemos
emplear la función <tt>plot()</tt> de la forma.

``` r
plot(x = datos$area_lote, y = datos$preciovtax, xlab = "Área del Lote", ylab = "Precio de venta (m2)", 
    main = "Relación entre Área del Lote y Precio de venta m2", pch = 19)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-26-1.png)

#### Más de dos variables Cuantitativas

**Matriz de dispersión**<br><br> Cuando se poseen más de dos variables
cuantitativas, es posible presentar un matriz que muestre el cruce entre
pares de variables, mediante cuadros con versiones simples de la función
<tt>plot()</tt>. Este gráfico puede ser realizado mediante la función
<tt>pairs()</tt> de la librería <tt>graphics</tt> de la base de
<tt>R</tt>.

Para ello, suponga que se desea observar la relación que hay entre las
variables, área del lote donde se construye la obra o proyecto
(<tt>area\_lote</tt>), porcentaje de avance de la obra en contrucción
(<tt>gradoavanc</tt>) y área total vendible por unidad
(<tt>areavenuni</tt>). Para ello empleamos la función <tt>pairs()</tt>
de la forma

``` r
## Matríz de dispersión básica
pairs(cbind(datos$area_lote, datos$gradoavanc, datos$areavenuni), labels = c("Área Lote", 
    "Porcentaje de Avance", "Área Total Vendible"))
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-27-1.png)

Funciones complementarias pueden ser desarrolladas para mejorar la
visualización los pares de variables. En el libro de Hernández & Correa
([2018](#ref-Hernandez2018), pp. 40–49), se presentan diferentes
funciones que pueden ser implementadas. Entre ellas la siguiente función

``` r
## Matríz de dispersión avanzada Función para dibujar la dispersión y agregar
## la recta de regresión
panel.reg <- function(x, y) {
    points(x, y, pch = 20)
    abline(lm(y ~ x), lwd = 2, col = "dodgerblue2")
}
# Función para crear el histograma
panel.hist <- function(x, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5))
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks
    nB <- length(breaks)
    y <- h$counts
    y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "dodgerblue2", ...)
}
# Función para obtener la correlación
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste(prefix, txt, sep = "")
    if (missing(cex.cor)) 
        cex <- 0.8
    text(0.5, 0.5, txt, cex = cex)
}

pairs(cbind(datos$area_lote, datos$gradoavanc, datos$areavenuni), labels = c("Área Lote", 
    "Porcentaje de Avance", "Área Total Vendible"), upper.panel = panel.reg, 
    diag.panel = panel.hist, lower.panel = panel.cor)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-28-1.png)

#### Una Variable Cualitativa

**Gráfico de barras**<br><br> Sirve para resumir una variable
cualitativa mediante barras de frecuencias absolutas o relativas. Éste
**permite observar la concentración de observaciones en una o más
categorías diferentes**. Este gráfico puede ser realizado mediante la
función <tt>barplot()</tt> de la librería <tt>graphics</tt> de la base
de <tt>R</tt>.

Para ilustrar su empleo, suponga que se desea observar el estado en el
cual se encontraron las obras al momento de realizar el censo
(<tt>estado\_act</tt>). En este caso, la función <tt>barplot()</tt> se
emplea de la siguiente forma

``` r
# Gráfico de barras
tabla1 <- table(datos$estado_ac)
barplot(tabla1, main = "Estado en el cual se encontraron las obras al momento del censo", 
    col = hcl.colors(6))
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-29-1.png)

**Gráfico de pareto**<br><br> Este gráfico es similar al gráfico de
barras para una sola variable cualitativa, pero con la ventaja de que
**presenta las frecuencias absolutas, relativas, y las frecuencias
acumuladas absolutas y acumuladas relativas en el mismo gráfico**. Este
gráfico puede ser realizado mediante la función <tt>pareto.chart()</tt>
de la librería <tt>qqc</tt>.

Para ilustrar su empleo, suponga que se desea observar el estrato
socioeconómico en donde se está realizado la obra (<tt>estrato</tt>). Al
ser una sola variable, la función <tt>pareto.chart()</tt> se emplea de
la siguiente forma

``` r
library(qcc)

# Gráfico de pareto
tabla2 <- table(datos$estrato)
pareto.chart(tabla2, main = "Gráfico Pareto por Estrato")
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-30-1.png)

       
    Pareto chart analysis for tabla2
           Frequency    Cum.Freq.   Percentage Cum.Percent.
      3 28138.000000 28138.000000    32.662395    32.662395
      2 25852.000000 53990.000000    30.008822    62.671217
      4 12452.000000 66442.000000    14.454195    77.125412
      1 11171.000000 77613.000000    12.967219    90.092631
      5  5011.000000 82624.000000     5.816734    95.909365
      6  3524.000000 86148.000000     4.090635   100.000000

**Gráfico de pastel**<br><br> Este gráfico también **sirve para
representar gráficamente las tablas de frecuencias absolutas y relativas
para una variable cualitativa**. A pesar de ser un gráfico muy usado en
la práctica, **no muestra bien la información que se desea presentar**,
ya que siempre debe estar acompañado de los porcentajes o frecuencias
que representa cada área, ya que no hacerlo, dicho gráfico puede ser muy
engañoso.

Este gráfico puede ser realizado mediante la función <tt>pie()</tt> de
la librería <tt>graphics</tt> de la base de <tt>R</tt>, y donde, para
establecer etiquetas de los porcentajes o frecuencias de cada área,
puede establecerse mediante la función <tt>legend()</tt> de la librería
<tt>graphics</tt> de la base de <tt>R</tt>.

Empleamos la variable del estado en que se encuentra la obra
(<tt>movimiento</tt>) para ilustrar el empleo del gráfico de pastel. En
dicho caso, la estructura de la función <tt>pie()</tt> y
<tt>legend()</tt> será de la forma

``` r
# Gráfico de pastel una variable de frecuencias absolutas
tabla3 <- prop.table(table(datos$movimiento))
pie(tabla3, main = "Estado en que se encuentra la obra", col = cm.colors(6))
legend("topleft", legend = paste0(names(tabla3), " (", round(tabla3, 4), ")"), 
    fill = cm.colors(6), cex = 0.8)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-31-1.png)

#### Dos Variables Cualitativas

**Gráfico de barras**<br><br> El gráfico de barras también sirve para
resumir dos variable cualitativa mediante barras de frecuencias
absolutas o relativas. **La interpretación, será la misma que para una
sola variable cualitativa, con la diferencia de que en este caso, se
podrán hacer comparaciones por categorías adicionales.** Este gráfico
puede ser realizado mediante la función <tt>barplot()</tt> de la
librería <tt>graphics</tt> de la base de <tt>R</tt>, junto a la función
<tt>legend()</tt>, para establecer las etiquetas asociadas a cada una de
las barras que se presenten en el gráfico.

Para ilustrar su empleo, suponga que se desea observar el estado en el
cual se encontraron las obras al momento de realizar el censo
(<tt>estado\_act</tt>), respecto a si la obra cuenta o no con licencia
(<tt>ob\_formal</tt>). En este caso, la función <tt>barplot()</tt> se
emplea junto a la función <tt>legend()</tt> de la siguiente forma

``` r
# Gráfico de barras
tabla4 <- table(datos$estado_ac, datos$ob_formal)
barplot(tabla4, main = "Estado de la obra respecto a si la obra cuenta o no con licencia", 
    col = hcl.colors(6), beside = T)
legend("topright", rownames(tabla4), fill = topo.colors(6), cex = 0.8)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-32-1.png)

**Gráfico de balón**<br><br> El gráfico de balón, suele ser un gráfico
más avanzado para resumir dos variable cualitativa, en donde **se
establecen en el cruce de las dos variables, círculos que se asocian al
tamaño del cruce de las dos variables cualitativas**. Este gráfico puede
ser realizado mediante la función <tt>ggballoonplot()</tt> de la
librería <tt>ggpubr</tt>, la cual depende de la librería
<tt>ggplot2</tt>.

Para ilustrar el empleo de la función, suponga que se desea observar el
estado en el cual se encontraron las obras al momento de realizar el
censo (<tt>estado\_act</tt>), respecto al estado en que se encuentra la
obra (<tt>movimiento</tt>). En este caso, la función
<tt>ggballoonplot()</tt> puede emplearse de la forma

``` r
library(ggplot2)
library(ggpubr)
theme_set(theme_pubr())

# Gráfico de balón
tabla5 <- data.frame(table(datos$estado_ac, datos$movimiento))
ggballoonplot(tabla5, fill = "value") + scale_fill_viridis_c(option = "C")
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-33-1.png)

#### Cruce entre Variables Cualitativas y Cuantitativas

**Gráfico de caja y bigotes**<br><br> Este gráfico sirve para presentar
de forma visual, datos numéricos **por categorías** a través de sus
cuartiles, además de presentar **otras características importantes,
tales como la dispersión, simetría y datos potencialmente atípicos**.
Este gráfico puede ser realizado mediante la función <tt>boxplot()</tt>
de la librería <tt>graphics</tt> de <tt>R</tt>.

Suponga que se tiene interés en realizar un cruce entre la variable
cualitativa que indica si la obra cuenta o no con licencia
(<tt>ob\_formal</tt>) y la variable cuantitativa del grado de avance de
la obra (<tt>gradoavanc</tt>). Para ello, puede emplearse el gráfico de
caja y bigotes de la forma

``` r
# Construcción de gráfico de caja y bigotes por categorías
boxplot(datos$gradoavanc ~ datos$ob_formal, horizontal = T, xlab = "Grado de avance", 
    ylab = "Posee licencia?", main = "Grado de avance respecto a la posesión de licencia", 
    col = terrain.colors(2))
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-34-1.png)

**Gráfico de medias**<br><br> Este gráfico **sirve para presentar de
forma visual, grupos de datos numéricos a través de sus media y
desviación estándar**. El gráfico está compuesto por un punto que
representa el valor promedio del grupo de observaciones y **las barras
representan dos desviación estándar de la media**. En donde, si las
barras no se superponen, entonces se tendrá evidencia sólida respecto a
que la media de los grupos es diferente.

Este gráfico puede ser realizado mediante la función
<tt>plotMeans()</tt> de la librería <tt>RcmdrMisc</tt>. Y para ilustrar
su empleo, suponga que se desea observar área total vendible
(<tt>areavendib</tt>), respecto al rango de vivienda calculado
(<tt>ranvivi</tt>). Ésto se puede realizar mediante la forma

``` r
library(RcmdrMisc)

## Construcción de diagrama de caja y bigotes por categorías Recordar
## escribir en error.bars = 'conf.int' porque por defecto se presenta un
## intervalo para el error estándar y no para dos desviaciones estándar.
plotMeans(response = datos$areavendib, factor1 = datos$ranvivi, error.bars = "conf.int", 
    xlab = "Área total vendible", ylab = "Rangos de vivienda", main = "Área vendible respecto a rangos de vivienda")
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-35-1.png)

Inferencia estadística
----------------------

La inferencia estadística es la obtención de conclusiones basadas en
datos experimentales. Para entender la naturaleza de la inferencia
estadística, se debe entender primero la diferencia entre “población” y
“muestra”.

**Población:** Consta del total de observaciones del suceso o proceso en
que estamos interesados. En muchas ocasiones, no es posible obtener o
replicar dicha información.

**Muestra:** Es un subconjunto de la población de interés, extraída con
el objetivo de hacer inferencia sobre la población.

**Muestra aleatoria:** Es un subconjunto de la población seleccionado de
forma independiente e idénticamente distribuidos (*iid* en adelante).

### Estadísticos muestrales

Son funciones de las variables aleatorias obtenidas a partir de muestras
aleatorias, que **tienen por objetivo estimar o hacer inferencia acerca
de parámetros desconocidos de una población**.

Entonces, si se tiene un conjunto de observaciones
`$X_1, X_2, \ldots, Xn$` obtenidas de una muestra aleatoria *iid* de
tamaño `$n$`, entonces se tendrán los siguientes estadísticos muestrales

#### Media muestral

Es el promedio aritmético del total de las `$n$` observaciones
pertenecientes a una muestra aleatoria. Éste estadístico se define como
`\begin{align*}   \bar{X}=\sum_{i=1}^n\frac{x_i}{n}=\frac{x_1+x_2+\ldots+x_n}{n} \end{align*}`

En <tt>R</tt>, puede calcularse el valor de la media muestral de una
muestra aleatoria mediante la función `mean(datos)`.

#### Varianza muestral

Es la distancia media **al cuadrado** del conjunto de observaciones
pertenecientes a una muestra aleatoria, respecto a la media muestra.
`\begin{align*}   S^2=\frac{1}{n-1}\sum_{i=1}^n{(x_i-\bar{X})^2} \end{align*}`

siendo el valor `$n-1$` conocido como la corrección de Bessel, el cuál
se usa en lugar de la división sobre `$n$` con el fin de corregir el
sesgo tendría el estimador.

En <tt>R</tt> puede calcularse la varianza muestral de una muestra
aleatoria mediante la función `var(datos)`.

#### Desviación estándar muestral

Es la raíz cuadrada de la distancia media **al cuadrado** del conjunto
de observaciones pertenecientes a una muestra aleatoria, respeto a la
media, es decir, indica qué tan dispersos se encuentra el conjunto de
observaciones de una muestra aleatoria respecto a su valor promedio.
`\begin{align*}   S=\sqrt{S^2} \end{align*}`

En <tt>R</tt> puede calcularse la desviación estándar de una muestra
aleatoria mediante la función `sd(datos)`.

#### Proporción muestral

Como su nombre lo indica, es la proporción de observaciones que cumplen
una condición específica dentro de una muestra, respecto al total de
observaciones dentro de la muestra, e indica el porcentaje de individuos
que cumplen una característica dentro de un conjunto de observaciones.

`\begin{align*}   \hat{p}= \frac{x}{n} = \frac{\text{Número de éxitos}}{\text{Total de observaciones}} \end{align*}`

En <tt>R</tt> puede calcularse la proporción de observaciones que cumple
una condición mediante la función `table(datos)`.

### Distribuciones muestrales

Debido a que **todos los estadístico** son funciones de las variables
aleatorias observadas en una muestra, se tendrá que, éstos también serán
variables aleatorias que **tendrán distribuciones de probabilidad
asociadas**, las cuales son llamadas distribuciones muestrales.

#### Distribución muestral `$Z$`

**Se usa para hacer inferencia sobre la media de una o dos
poblaciones.**. Para el caso de una población, sea
`$X_1, X_2, \ldots, X_n$` una muestra aleatoria de tamaño `$n$` de una
distribución normal con media `$\mu$` y varianza `$\sigma^2$` conocida,
entonces se tendrá que
`\begin{align*} Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1) \end{align*}`

se distribuirá como una normal estándar de forma exacta.

Mientras que, para el caso de dos poblaciones, sea
`$X_{11}, X_{12}, \ldots, X_{1n_1}$` y
`$X_{21}, X_{22}, \ldots, X_{2n_1}$` dos muestras aleatorias *iid* con
medias `$\mu_1$` y `$\mu_2$`, y varianzas `$\sigma_1^2$` y
`$\sigma_2^2$`, para `$i=1,2,\ldots,n_1$` y `$j=1,2,\ldots,n_2$`,
entonces se tendrá que

`\begin{align*} Z_c=\frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}}} \sim N(0,1) \end{align*}`

se distribuirá como una normal estándar de forma exacta.

#### Teorema del límite central

**Se usa para hacer inferencia sobre la media de una o dos
poblaciones**. Para el caso de una población, sea
`$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* con media `$\mu$`
y varianza `$\sigma^2$` entonces, cuando `$n\to \infty$`, se tendrá que
`\begin{align*} Z_c = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \stackrel{a}{\sim} N(0,1) \end{align*}`
tendrá una distribución aproximadamente normal estándar, cuando
`$n\sim \infty$`.

Para el caso de dos poblaciones, sea
`$X_{11}, X_{12}, \ldots, X_{1n_1}$` y
`$X_{21}, X_{22}, \ldots, X_{2n_1}$` dos muestras aleatorias *iid* con
medias `$\mu_1$` y `$\mu_2$`, y varianzas `$\sigma_1^2$` y
`$\sigma_2^2$`, para `$i=1,2,\ldots,n_1$` y `$j=1,2,\ldots,n_2$`,
entonces se tendrá que

`\begin{align*} Z_c=\frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}}} \stackrel{a}{\sim} N(0,1) \end{align*}`

tendrá una distribución aproximadamente normal estándar, cuando
`$n\sim \infty$`.

#### Distribución muestral `$t$` de Student

**Se usa para hacer inferencia sobre la media de una o dos
poblaciones**. Para el caso de una población, sea
`$X_1, X_2, \ldots, X_n$` una muestra aleatoria de una población normal
con media `$\mu$` y varianza `$\sigma^2$` desconocida, se tendrá

`\begin{align*} t_c = \frac{\bar{X}-\mu}{S/\sqrt{n}} \sim t_{n-1} \end{align*}`

tiene una distribución `$t$` con `$(n-1)$` grados de libertad.

Mientras que, para el caso de dos poblaciones, sea
`$X_{11}, X_{12}, \ldots, X_{1n_1}$` y
`$X_{21}, X_{22}, \ldots, X_{2n_1}$` dos muestras aleatorias *iid* con
medias `$\mu_1$` y `$\mu_2$`, y varianzas `$\sigma_1^2$` y
`$\sigma_2^2$` desconocidas, para `$i=1,2,\ldots,n_1$` y
`$j=1,2,\ldots,n_2$`, entonces si se cumple que
`$\sigma_1^2=\sigma_2^2$`, se tendrá que

`\begin{align*} t_c=\frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{S_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t_{n_1+n_2-2} \end{align*}`
donde
`\begin{align*} S_p^2 = \frac{(n_1-1)S^2_1+(n_2-1)S^2_2}{n_1+n_2-2} \end{align*}`

o si se cumple que `$\sigma_1^2\neq\sigma_2^2$`, se tendrá que

`\begin{align*} t_c=\frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2}}} \sim t_\nu \end{align*}`
donde
`\begin{align*} \lceil\nu\rceil = \frac{\left(\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}\right)^2}{\left[\frac{(S_1^2/n_1)^2}{n_1-1}\right] + \left[\frac{(S_2^2/n_2)^2}{n_2-1}\right]} \end{align*}`

En estos dos casos, `$t_c$` se distribuirá como una `$t$` con
`$(n_1+n_2-1)$` grados de libertad o `$(n-1)$` grados de libertad,
respectivamente.

#### Distribución muestral `$F$` de Fisher-Snedecor

**Se usa para hacer inferencia sobre la varianza de dos poblaciones**.
Si `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_2}$` son dos muestras aleatorias
independientes de poblaciones normales con medias `$\mu_1, \mu_2$` y
varianzas `$\sigma^2_1, \sigma^2,2$`, respectivamente, entonces

`\begin{align*} F_c = \frac{S^2_1\sigma^2_2}{S^2_2\sigma^2_1} \sim F_{n_1-1, n_2-1} \end{align*}`

tienen una distribución `$F$` con `$n_1-1$` grados de libertad en el
numerador y `$n_2-1$` grados de libertad en el denominador.

#### Distribución muestral para proporciones `$p$`

**Se usa para hacer inferencia sobre la proporción de una o dos
poblaciones**. Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid*
de tamaño `$n$`, tal que `$X\sim b(n,p)$`. Entonces si `$n$` es
suficientemente grande, y la proporción `$p$` no está muy cercana a
`$0$` o a `$1$`, tal que `$np$` y `$n(1-p)>5$`, entonces se puede probar
que
`\begin{align*} \hat{p}  = \frac{x}{n} \stackrel{a}{\sim} N\left(p, \frac{p(1-p)}{n}\right) \end{align*}`
donde por teorema de estandarización se obtendrá que
`\begin{align*} Z_c = \frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}} \stackrel{a}{\sim} N(0,1) \end{align*}`

### Intervalos de confianza

Un intervalo de confianza **es un rango de valores**, construidos a
partir de los estadísticos muestrales, **que tienen por objetivo,
incluir** con un nivel de confianza preestablecido, **el valor real de
un parámetro desconocido de una población**.

**Nota**<br>
<ol type="a">
<li>
Usualmente se usan valores de de \(0.1, 0.05\) y $ 0.01$, es decir,
niveles de confianza de \(0.9, 0.95\) y \(0.99\).
</li>
<li>
La longitud o amplitud del intervalo construido, medirá la
<strong>precisión</strong> de la estimación realizada, por tanto,
intervalos largos proporcionan estimaciones más imprecisas, mientras que
intervalos cortos proporcionan estimaciones más precisas.
</li>
<li>
A medida que aumenta el nivel de confianza, la amplitud del intervalo se
hace más grande.
</li>
<li>
A medida que aumenta el tamaño de muestra, la amplitud del intervalo se
hace más pequeño.
</li>
</ol>

Para facilitar el cálculo de cualquier intervalo, se crean funciones que
puede ser descargada mediante la siguiente linea de código

``` r
## Código descargar funciones para intervalos
fun.int <- tempfile(fileext = ".R")  # Crea archivo temporal
URL <- "https://raw.githubusercontent.com/jouninLRMD/jouninlrmd.github.io/master/Dataset/Codigos%20R/Intervalos.R"  # URL base de datos
download.file(URL, destfile = fun.int, mode = "wb")  # Descarga archivo en el archivo temporal creado

source(fun.int)  # Carga funciones guardadas
```

#### Intervalos de confianza para una media `$\mu$`

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño
`$n$` con media `$\mu$` desconocida, y varianza `$\sigma^2<\infty$`,
entonces dependiendo de las condiciones, se tendrán los siguientes
intervalos de confianza para la media `$\mu$`.

![](../SesionesEspeciales/images/Intervalos1.jpg)

Suponga que se desea crear un intervalo de confianza del `$90\%$` para
el número promedio de pisos de la construcción (<tt>nro\_pisos</tt>). En
este caso, una vez descargadas las funciones para intervalos, podemos
calcular un intervalo de confianza para una media en <tt>R</tt> mediante
la función <tt>IntUnaMedia</tt> de la forma

``` r
# Calcula intervalo de confianza para una media creada
IntUnaMedia(datos = datos$nro_pisos, nivel.conf = 0.9)
```

Similarmente, puede emplearse la función <tt>t.test()</tt> de
<tt>R</tt>, que permite probar la situación en donde la varianza
poblacional no es conocida, y la distribución es normal.

``` r
# Calcula intervalo de confianza para una media R
t.test(x = datos$nro_pisos, conf.level = 0.9)
```


        One Sample t-test

    data:  datos$nro_pisos
    t = 267.18, df = 86146, p-value < 2.2e-16
    alternative hypothesis: true mean is not equal to 0
    90 percent confidence interval:
     3.303944 3.344877
    sample estimates:
    mean of x 
     3.324411 

#### Intervalos de confianza para diferencia de medias `$\mu_1 - \mu_2$`

Sea `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias *iid* de
tamaños `$n_1$`, y `$n_2$` con medias `$\mu_1$` y `$\mu_2$`
desconocidas, y varianzas `$\sigma_1^2<\infty$` y `$\sigma^2_2<\infty$`,
respectivamente, entonces dependiendo de las condiciones, se tendrán los
siguientes intervalos de confianza para la diferencia de medias
`$\mu_1 - \mu_2$`.

![](../SesionesEspeciales/images/Intervalos2.jpg)

Suponga que se desea crear un intervalo de confianza del `$95\%$` para
la diferencia promedio entre el precio de venta por `$m^2$`
(<tt>preciovtax</tt>), en los estratos `$2$` y `$4$` (<tt>estrato</tt>).
En este caso, una vez descargadas las funciones para intervalos, podemos
calcular un intervalo de confianza para la diferencia de media en
<tt>R</tt> mediante la función <tt>IntDosMedias</tt> de la forma

``` r
# Calcula intervalo de confianza para diferencia de medias creada
IntDosMedias(datos1 = datos$preciovtax[datos$estrato == 2], datos2 = datos$preciovtax[datos$estrato == 
    4], nivel.conf = 0.95)
```

Similarmente, puede emplearse la función <tt>t.test()</tt> de
<tt>R</tt>, que permite probar la situación en donde las varianzas
poblacionales no son conocidas, y las distribuciones son normal y se
puede establecer si las varianzas poblacionales son o no iguales.

``` r
# Calcula intervalo de confianza para diferencia de medias R
t.test(x = datos$preciovtax[datos$estrato == 2], y = datos$preciovtax[datos$estrato == 
    4], conf.level = 0.95, var.equal = F)
```


        Welch Two Sample t-test

    data:  datos$preciovtax[datos$estrato == 2] and datos$preciovtax[datos$estrato == 4]
    t = -131.04, df = 14252, p-value < 2.2e-16
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     -1254.805 -1217.818
    sample estimates:
    mean of x mean of y 
     938.2444 2174.5557 

#### Intervalos de confianza para una proporción `$p$`

Sea `$X_1,X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño
`$n$`, tal que `$X\sim b(n,p)$` entonces si `$n$` es suficientemente
grande tal que `$n\geq30$`, y la proporción desconocida `$p$` no se
encuentre cercana a `$0$` o `$1$`, tal que `$np>5$` y `$n(1-p)>5$`,
entonces un intervalo de confianza para la proporción `$p$` es de la
forma ![](../SesionesEspeciales/images/Intervalos3.jpg)

Suponga que se desea crear un intervalo de confianza del `$90\%$` para
la proporción de empresas que poseen licencia de construcción
(<tt>ob\_formal</tt>). En este caso, una vez descargadas las funciones
para intervalos, podemos calcular un intervalo de confianza para una
proporción en <tt>R</tt> mediante la función <tt>IntDosMedias</tt> de la
forma

``` r
# Calcula intervalo de confianza para una proporción creada
IntUnaProp(datos = datos$ob_formal, factor = "Sí", nivel.conf = 0.9)
```

Similarmente, puede emplearse la función <tt>prop.test()</tt> de
<tt>R</tt>, de la forma

``` r
# Calcula intervalo de confianza para una proporción R
exitos <- table(datos$ob_formal)[1]
total <- sum(table(datos$ob_formal))
prop.test(x = exitos, n = total, conf.level = 0.9)
```


        1-sample proportions test with continuity correction

    data:  exitos out of total, null probability 0.5
    X-squared = 9080.5, df = 1, p-value < 2.2e-16
    alternative hypothesis: true p is not equal to 0.5
    90 percent confidence interval:
     0.3350122 0.3403242
    sample estimates:
            p 
    0.3376631 

#### Intervalos de confianza para diferencia de proporciones `$p_1 - p_2$`

Sea `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias *iid* de
tamaños `$n_1$`, y `$n_2$` tal que `$X_1\sim b(n,p)$` y
`$X_2\sim b(n,p)$`. Entonces si, `$n_1$`, y `$n_2$` son suficientemente
grandes tal que `$n_1, n_2 \geq 30$`, y las proporciones desconocidas
`$p_1$` y `$p_2$` no se encuentran cercanas a `$0$` o `$1$`, tal que
`$n_1p_1, n_2p_2, n_1(1-p_1)$` y `$n_2(1-p_2)>5$`, entonces un intervalo
de confianza para la diferencia de proporciones `$p_1 - p_2$` es de la
forma

![](../SesionesEspeciales/images/Intervalos5.jpg)

Suponga que se desea crear un intervalo de confianza del `$90\%$` para
la diferencia entre la proporción de empresas que poseen licencia de
construcción (<tt>ob\_formal</tt>), respecto a las regiones de Bogotá y
Antioquia (<tt>region</tt>). En este caso, una vez descargadas las
funciones para intervalos, podemos calcular un intervalo de confianza
para la diferencia entre proporción en <tt>R</tt> mediante la función
<tt>IntDosProp</tt> de la forma

``` r
# Calcula intervalo de confianza para diferencia de proporciones creada
IntDosProp(datos1 = datos$ob_formal[datos$region == "Bogotá"], datos2 = datos$ob_formal[datos$region == 
    "Antioquia"], factor1 = "Sí", factor2 = NULL, nivel.conf = 0.9)
```

Similarmente, puede emplearse la función <tt>prop.test()</tt> de
<tt>R</tt>, de la forma

``` r
# Calcula intervalo de confianza para diferencia de proporciones R
exitos1 <- table(datos$ob_formal[datos$region == "Bogotá"])[1]
total1 <- sum(table(datos$ob_formal[datos$region == "Bogotá"]))
exitos2 <- table(datos$ob_formal[datos$region == "Antioquia"])[1]
total2 <- sum(table(datos$ob_formal[datos$region == "Antioquia"]))
prop.test(x = c(exitos1, exitos2), n = c(total1, total2), conf.level = 0.9)
```


        2-sample test for equality of proportions with continuity
        correction

    data:  c(exitos1, exitos2) out of c(total1, total2)
    X-squared = 52.232, df = 1, p-value = 0.0000000000004933
    alternative hypothesis: two.sided
    90 percent confidence interval:
     -0.05258971 -0.03289650
    sample estimates:
       prop 1    prop 2 
    0.4006542 0.4433973 

#### Intervalos de confianza para razón de varianzas `$\sigma^2_1/\sigma^2_2$`

Sea `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias normales
de tamaños `$n_1$`, y `$n_2$` con medias `$\mu_1$` y `$\mu_2$`, y
varianzas desconocidas `$\sigma_1^2<\infty$` y `$\sigma^2_2<\infty$`,
respectivamente, entonces un intervalo de confianza del
`$100(1-\alpha)\%$` para `$\sigma^2_1/\sigma^2_2$` estará dada por

![](../SesionesEspeciales/images/Intervalos4.jpg)

Suponga que se desea crear un intervalo de confianza del `$95\%$` para
el cociente de varianzas entre el precio de venta por `$m^2$`
(<tt>preciovtax</tt>), en los estratos `$1$` y `$5$` (<tt>estrato</tt>).
En este caso, una vez descargadas las funciones para intervalos, podemos
calcular un intervalo de confianza para la diferencia de media en
<tt>R</tt> mediante la función <tt>IntCosVar</tt> de la forma

``` r
# Calcula intervalo de confianza para cociente de varianzas creada
IntCosVar(datos1 = datos$preciovtax[datos$estrato == 1], datos2 = datos$preciovtax[datos$estrato == 
    5], nivel.conf = 0.95)
```

Similarmente, puede emplearse la función <tt>var.test()</tt> de
<tt>R</tt>, de la forma

``` r
# Calcula intervalo de confianza para cociente de varianzas R
var.test(x = datos$preciovtax[datos$estrato == 1], y = datos$preciovtax[datos$estrato == 
    5], conf.level = 0.95)
```


        F test to compare two variances

    data:  datos$preciovtax[datos$estrato == 1] and datos$preciovtax[datos$estrato == 5]
    F = 0.034198, num df = 11170, denom df = 5010, p-value < 2.2e-16
    alternative hypothesis: true ratio of variances is not equal to 1
    95 percent confidence interval:
     0.03261627 0.03584061
    sample estimates:
    ratio of variances 
            0.03419778 

### Prueba de hipótesis

Una hipótesis estadística **es una afirmación o conjetura que se realiza
sobre una población o sobre los parámetros de la misma**, en donde el
objetivo es decidir si la afirmación hecha se encuentra apoyada por la
información obtenida de una muestra de la población de interés.

#### Componentes de una prueba de hipótesis

**Hipótesis nula**<br><br> Sea `$\theta$` un parámetro de interés
desconocido y sea `$\theta_0$` un valor particular de `$\theta$`,
entonces se tendrá que la hipótesis nula estará dado por

-   **Bilateral** `$H_0: \theta = \theta_0$`
-   **Unilateral izquierda** `$H_0: \theta \geq \theta_0$`
-   **Unilateral derecho** `$H_0: \theta \leq \theta_0$`

matemáticamente `$H_0: \theta \geq \theta_0$` y
`$H_0: \theta \leq \theta_0$` es matemáticamente equivalente a escribir
`$H_0: \theta = \theta_0$` y por tanto, se acostumbra a usar esta última
en los tres casos.

**Hipótesis alternativa**<br><br> Es el complemento lógico de la
hipótesis nula, y por tanto, ésta estará dado por

-   **Bilateral** `$H_0: \theta \neq \theta_0$`
-   **Unilateral izquierda** `$H_0: \theta < \theta_0$`
-   **Unilateral derecho** `$H_0: \theta > \theta_0$`

Ésta hipótesis no puede contener la igualdad, a menos que se quiera una
hipótesis alternativa específica.

**Estadístico de prueba**<br><br> El estadístico de prueba será el valor
usado para tomar la decisión entre `$H_0$` y `$H_1$`. Éste dependerá del
parámetro de interés y de la distribución muestral del estadístico
asociado.

**P-valor**<br><br> Es el nivel de significancia más bajo en el que el
valor observado del estadístico de prueba es significativo. Por tanto,
un valor relativamente pequeño puede sugerir que el valor observado del
estadístico de prueba sea poco probable, y por tanto, `$H_0$` deba ser
rechazado.

En general, como criterio de decisión para el P-valor, dado un nivel de
significancia preestablecido, es de la forma
`\begin{align*} \text{P-valor }<\alpha \Rightarrow \text{ Rechazar } H_0 \end{align*}`

#### Prueba de hipótesis para la media `$\mu$`

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño
`$n$` con media desconocida `$\mu$`, y varianza `$\sigma^2<\infty$`,
entonces dependiendo de las condiciones, se tendrán los siguientes
pruebas de hipótesis para la media `$\mu$`.

![](../SesionesEspeciales/images/Hipotesis3.jpg)

Suponga que se desea probar con nivel de significancia del `$5\%$`, la
hipótesis de que el número promedio en `$m^2$` de las áreas comunes es
superior a `$154$` `$m^2$` (<tt>areatotzc</tt>). Para realizar la prueba
de hipótesis para una media, bajo los supuestos de que, la distribución
es normal o aproximadamente normal y que la varianza poblacional no es
conocidas, puede emplearse la función <tt>t.test()</tt> de <tt>R</tt>,
de la forma

``` r
# Calcula pueba de hipótesis para una media
t.test(x = datos$areatotzc, mu = 154, alternative = "greater", conf.level = 0.95)
```


        One Sample t-test

    data:  datos$areatotzc
    t = 0.39854, df = 86143, p-value = 0.3451
    alternative hypothesis: true mean is greater than 154
    95 percent confidence interval:
     151.2926      Inf
    sample estimates:
    mean of x 
     154.8657 

#### Prueba de hipótesis para diferencia de medias `$\mu_1 - \mu_2$`

Sea `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias *iid* de
tamaños `$n_1$`, y `$n_2$` con medias desconocidas
`$\mathbb{E}(X_{1})=\mu_1$` y `$\mathbb{E}(X_{2})=\mu_2$`, y varianzas
`$Var(X_{1})=\sigma_1^2<\infty$` y `$Var(X_{2})=\sigma^2_2<\infty$`,
respectivamente, entonces dependiendo de las condiciones, se tendrán los
siguientes pruebas de hipótesis para la diferencia de medias
`$\mu_1 - \mu_2$`.

![](../SesionesEspeciales/images/Hipotesis4.jpg)

Suponga que se desea probar con nivel de significancia del `$1\%$`, la
hipótesis de que el precio promedio de venta por `$m^2$` en Antioquia,
es menor que el precio promedio de venta por `$m^2$` en el Valle
(<tt>preciovtax</tt>) y (<tt>region</tt>).

Basados en los supuestos de normalidad, y varianzas desconocidas, en
<tt>R</tt> es posible emplear la función <tt>t.test()</tt> para probar
la hipótesis de interés. Tal como se muestra a continuación.

``` r
# Calcula pueba de hipótesis para una media
t.test(x = datos$preciovtax[datos$region == "Antioquia"], y = datos$preciovtax[datos$region == 
    "Valle"], mu = 0, alternative = "less", conf.level = 0.99)
```


        Welch Two Sample t-test

    data:  datos$preciovtax[datos$region == "Antioquia"] and datos$preciovtax[datos$region == "Valle"]
    t = 66.884, df = 16153, p-value = 1
    alternative hypothesis: true difference in means is less than 0
    99 percent confidence interval:
         -Inf 910.2621
    sample estimates:
    mean of x mean of y 
     2090.394  1210.732 

#### Prueba de hipótesis para una proporción `$p$`

Sea `$X_1,X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño
`$n$`, tal que `$X\sim b(n,p)$` entonces si `$n$` es suficientemente
grande tal que `$n\geq30$`, y la proporción desconocida `$p$` no se
encuentre cercana a `$0$` o `$1$`, tal que `$np>5$` y `$n(1-p)>5$`,
entonces un una prueba de hipótesis para la proporción verdadera `$p$`
será de la forma

![](../SesionesEspeciales/images/Hipotesis5.jpg)

Suponga que se desea probar con nivel de significancia del `$10\%$`, la
hipótesis de que la proporción de viviendas de interés social es
superior al `$43\%$` (<tt>tipovivi</tt>). En este caso, es posible
emplear la función <tt>prop.test</tt> de </tt>R</tt> para probar la
hipótesis de interés.

``` r
# Calcula prueba de hipótesis para una proporcion
exitos3 <- table(datos$tipovivi)[1]
total3 <- sum(table(datos$tipovivi))
prop.test(x = exitos3, n = total3, conf.level = 0.9, alternative = "greater", 
    p = 0.43)
```


        1-sample proportions test with continuity correction

    data:  exitos3 out of total3, null probability 0.43
    X-squared = 255.82, df = 1, p-value = 1
    alternative hypothesis: true p is greater than 0.43
    90 percent confidence interval:
     0.4008701 1.0000000
    sample estimates:
            p 
    0.4030157 

#### Prueba de hipótesis para diferencia de proporciones `$p_1 - p_2$`

Sean `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias *iid* de
tamaño `$n_1$` y `$n_2$`, tal que `$X_{i}\sim b(n_i,p_i)$`, para
`$i=1,2$`, entonces si `$n_1$` y `$n_2$` son suficientemente grandes tal
que `$n_1, n_2\geq30$`, y si las proporciones desconocidas `$p_1$` y
`$p_2$` no se encuentran cercanas a `$0$` o `$1$`, tal que `$n_ip_i>5$`
y `$n_i(1-p_i)>5$`, para `$i=1,2$`, entonces un una prueba de hipótesis
para la diferencia de las proporciones `$p_1-p_2$` será de la forma

![](../SesionesEspeciales/images/Hipotesis6.jpg)

Suponga que se tiene interés en probar la hipótesis si la proporción de
viviendas de interés social en el `$2016$` es inferior a la proporción
de viviendas de interés social en el `$2018$` (<tt>tipovivi</tt>) y
(<tt>ano\_censo</tt>), empleando un nivel de significancia del `$12\%$`.
En este caso, puede emplearse la función <tt>prop.table</tt> de
</tt>R</tt>, mediante la estructura

``` r
# Calcula intervalo de confianza para diferencia de proporciones R
exitos4 <- table(datos$tipovivi[datos$ano_censo == "2016"])[1]
total4 <- sum(table(datos$tipovivi[datos$ano_censo == "2016"]))
exitos5 <- table(datos$tipovivi[datos$ano_censo == "2018"])[1]
total5 <- sum(table(datos$tipovivi[datos$ano_censo == "2018"]))
prop.test(x = c(exitos4, exitos5), n = c(total4, total5), conf.level = 0.88, 
    alternative = "less")
```


        2-sample test for equality of proportions with continuity
        correction

    data:  c(exitos4, exitos5) out of c(total4, total5)
    X-squared = 4.4719, df = 1, p-value = 0.01723
    alternative hypothesis: less
    88 percent confidence interval:
     -1.000000000 -0.005788361
    sample estimates:
       prop 1    prop 2 
    0.3549380 0.3680311 

#### Prueba de hipótesis para cociente de varianzas `$\sigma^2_1/\sigma^2_2$`

Sea `$X_{1,1}, X_{1,2}, \ldots, X_{1,n_1}$` y
`$X_{2,1}, X_{2,2}, \ldots, X_{2,n_1}$` dos muestras aleatorias normales
de tamaños `$n_1$`, y `$n_2$` con medias `$\mathbb{E}(X_{1})=\mu_1$` y
`$\mathbb{E}(X_{2})=\mu_2$`, y varianzas desconocidas
`$Var(X_{1})=\sigma_1^2<\infty$` y `$Var(X_{2})=\sigma^2_2<\infty$`,
respectivamente, entonces un contraste de hipótesis para el cociente de
varianzas `$\sigma^2_1/\sigma^2_2$`, a un nivel de significancia
`$\alpha$` será de la forma

![](../SesionesEspeciales/images/Hipotesis7.jpg)

Empleando un nivel de significancial del `$5\%$`, verifique si existe
evidencia significativa respecto a que la variabilidad del área de los
lotes, es diferente para las viviendas de interés social y las viviendas
que no son de interés social (<tt>area\_lote</tt>) y
(<tt>tipovivi</tt>).

En este caso, como la hipótesis de interés es probar si la varianza
entre dos poblaciones es o no igual, es posible usar la función
<tt>var.test()</tt> de <tt>R</tt> de la forma

``` r
# Calcula intervalo de confianza para cociente de varianzas R
var.test(x = datos$area_lote[datos$tipovivi == "Social"], y = datos$area_lote[datos$tipovivi == 
    "No Social"], ratio = 1, alternative = "two.sided", conf.level = 0.95)
```


        F test to compare two variances

    data:  datos$area_lote[datos$tipovivi == "Social"] and datos$area_lote[datos$tipovivi == "No Social"]
    F = 2.0344, num df = 34718, denom df = 51428, p-value < 2.2e-16
    alternative hypothesis: true ratio of variances is not equal to 1
    95 percent confidence interval:
     1.995607 2.073951
    sample estimates:
    ratio of variances 
              2.034365 

### Prueba de bondad de ajuste

Las pruebas de bondad de ajuste **son un contraste de hipótesis para
determinar el grado o nivel de ajuste de nuestros datos a una
distribución teórica**.

Estas pruebas se basan en la comparación de las frecuencias de
ocurrencia observadas en una muestra empírica y las frecuencias
esperadas de una distribución teórica. En donde, el objetivo será si
existe o no discrepancia entre los valores observados y los valores
esperados de la distribución de interés.

La hipótesis a probar de interés estará dada por
`\begin{align*} H_0: X \sim F_0(x) \quad \text{vs} \quad H_1: X \nsim F_0(x) \end{align*}`

Siendo `$F_0(x)$` la distribución de probabilidad hipótetica que se
quiere probar.

Entre las pruebas de bondad de ajuste más usadas se tiene:

<pre style="font-family: 'Open Sans',sans-serif; margin-bottom: -3rem; margin-top: -3rem; font-size: 120%;">
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Prueba </th>
   <th style="text-align:left;"> Librería </th>
   <th style="text-align:left;"> Función </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Kolmogorov–Smirnov </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> ks.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Cramér–von Mises </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> w2.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Anderson–Darling </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> ad.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Kuiper </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> v.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> QQPlot </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> qqPlot </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Kolmogorov–Smirnov </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> ks.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Cramér–von Mises </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> w2.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Anderson–Darling </td>
   <td style="text-align:left;"> truncgof </td>
   <td style="text-align:left;"> ad.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Kuiper </td>
   <td style="text-align:left;"> car </td>
   <td style="text-align:left;"> v.test() </td>
  </tr>
</tbody>
</table>
</pre>

Donde éstas pruebas, **requieren de los parámetros de la distribución
que se quiere probar**, y para encontrarlos, es posible emplear
**métodos de optimización** que nos permitan observar cuales son los
parámetros ajustados para un conjunto de datos determinado. Para emplear
estos método de optimización es posible usar la función
<tt>fitdistr()</tt> de la librería <tt>MASS</tt>.

Para ilustrar el método de empleo, suponga que se desea probar si, el
área del lote (<tt>area\_lote</tt>), posee el comportamiento de una
distribución Weibull. Entonces, para probar esta distribución, será
necesario usar la función <tt>fitdistr()</tt> para encontrar los
parámetros que nos servirán para el ajuste, y posteriormente emplear una
prueba de bondad de ajuste, como por ejemplo la Kuiper y el gráfico QQ,
para saber si se rechaza o no la hipótesis de interés.

``` r
library(MASS)
## Se hace el ajuste para encontrar el valor de los parámetros
parametros <- fitdistr(na.omit(datos$area_lote), densfun = "weibull")

## Se hace la prueba de bondad de ajuste
truncgof::v.test(na.omit(datos$area_lote), distn = "pweibull", fit = list(shape = parametros$estimate[1], 
    scale = parametros$estimate[2]))
```


        Kuiper Test

    data:  na.omit(datos$area_lote)
    V = 138.16, p-value < 2.2e-16
    alternative hypothesis: NA

    treshold = -Inf, simulations: 100

``` r
## Se hace el QQplot
car::qqPlot(na.omit(datos$area_lote), dist = "weibull", shape = parametros$estimate[1], 
    scale = parametros$estimate[2])
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-53-1.png)

    [1] 3806 7530

Adicionalmente, existen pruebas específicas para probar si los datos se
distribuyen o no normalmente

<pre style="font-family: 'Open Sans',sans-serif; margin-bottom: -3rem; margin-top: -3rem; font-size: 120%;">
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Prueba </th>
   <th style="text-align:left;"> Librería </th>
   <th style="text-align:left;"> Función </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Shapiro-Wilk </td>
   <td style="text-align:left;"> stats* </td>
   <td style="text-align:left;"> shapiro.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Lilliefors </td>
   <td style="text-align:left;"> nortest </td>
   <td style="text-align:left;"> lillie.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Shapiro-Francia </td>
   <td style="text-align:left;"> nortest </td>
   <td style="text-align:left;"> sf.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Cramer Von-Mises </td>
   <td style="text-align:left;"> nortest </td>
   <td style="text-align:left;"> cvm.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Anderson-Darling </td>
   <td style="text-align:left;"> nortest </td>
   <td style="text-align:left;"> ad.test() </td>
  </tr>
  <tr>
   <td style="text-align:left;"> QQPlot </td>
   <td style="text-align:left;"> car </td>
   <td style="text-align:left;"> qqPlot </td>
  </tr>
</tbody>
</table>
</pre>

Para ilustrar el método de empleo de las pruebas de normalidad, suponga
que se desea probar si, el área total vendible (<tt>areavenuni</tt>), se
distribuye normalmente. Suponga que en este caso decidimos emplear la
prueba Lilliefors para probar la hipótesis. (Se decide emplear ésta
prueba debido a que otras prueden generar problemas debido a la cantidad
tan grande de datos)

``` r
## Se hace la prueba de bondad de ajuste de normalidad
nortest::lillie.test(datos$areavenuni)
```


        Lilliefors (Kolmogorov-Smirnov) normality test

    data:  datos$areavenuni
    D = 0.17805, p-value < 2.2e-16

Y también se decide visualizar la prueba de normalidad, mediante el
gráfico QQ, de la forma

``` r
## Se hace la prueba de bondad de ajuste de normalidad
car::qqPlot(datos$areavenuni)
```

![](../SesionesEspeciales/images/SesionEsp01unnamed-chunk-56-1.png)

    [1] 41015 17823

Referencias
-----------

<h7 id="ref-Esquivel2016"></h7> <h7 id="ref-Hernandez2018"></h7>
<h7 id="ref-Recchioni2016"></h7>

Esquivel, E. (2016). La enseñanza de la estadı́stica y la probabilidad,
más allá de procedimientos y técnicas. *Cuadernos de Investigación Y
Formación En Educación Matemática*, 21–31.

Hernández, F., & Correa, J. (2018). *Gráficos con r*. Universidad
Nacional de Colombia.

Recchioni, L. (2016). Evaluación de las polı́ticas públicas: Relevancia
de la estadı́stica. *Oikonomos*, *1*.

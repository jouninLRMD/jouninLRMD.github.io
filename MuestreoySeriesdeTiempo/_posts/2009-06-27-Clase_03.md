---
layout: post
title: "Clase 03"
main-class: 'clase'
permalink: /MuestreoySeriesdeTiempo/MyST:title.html
tags:

introduction: |
  Medidas de error o evaluación de los pronósticos.
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../MuestreoySeriesdeTiempo/_posts/", output_format = "all"  ) })
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
link-citations: yes
---







Evaluación de los pronósticos
-----------------------------

Otro aspecto de suma importancia en los pronósticos, es evaluar la
precisión o eficiencia del método de pronóstico empleado, y para ello,
se emplean diferentes indicadores que permiten identificar qué tan
acertado o cercano es el pronostico realizado respecto a su valor
original.

Para aplicar dichos métodos, una alternativa es la implementación de un
procedimiento conocido como *validación cruzada*, el cual consta de
dividir el conjunto de observaciones de la serie en dos grupos. El
primer grupo estará dado por las observaciones
`$\{Y_1, Y_2, \ldots, Y_{T-m}\}$`, denotadas como datos de
entrenamiento, y serán las observaciones que se emplearán para realizar
la estimación del modelo y estimación de los pronósticos. El segundo
grupo estará dado por las observaciones
`$\{Y_{T-m+1}, Y_{T-m+2}, \ldots, Y_{T}\}$`, denotadas como datos de
validación, y serán las observaciones que se emplearán para evaluar el
desempeño de los modelos.

Entonces, suponga que a partir del conjunto de entrenamiento se realizan
los pronósticos
`$\{\hat{Y}_{T-m+1}, \hat{Y}_{T-m+2}, \ldots, \hat{Y}_{T}\}$`, entonces
puede definirse el error de estimación `$e_t=\hat{varepsilon}_t$`, entre
las observación real `$t$` y el valor pronosticado `$t$`, de la forma
`\begin{align*} e_t= Y_t - \hat{Y}_t \end{align*}`

con `$t={T-m+1}, {T-m+2}, \ldots, {T}$`. A partir de los errores de
estimación `$e_t$`, es posible realizar el cálculo de diferentes medidas
de error que permitan cuantificar diferentes aspectos de los valores
pronosticados. Con el fin de ilustrar y mejorar el entendimiento de las
medidas de error, se presentarán las propiedades que posee cada uno de
ellos, basados en Adhikari and Agrawal ([2013](#ref-Adhikari2013), p.
42).

### Error medio (ME)

Esta medida está definida como
`\begin{align*} ME=\frac{1}{m}\sum_{t=T-m+1}^T e_t  \end{align*}`

-   Es una medida de la desviación promedio de los valores pronosticados
    respecto a los valores reales.
-   Muestra la dirección del error y, en consecuencia, el sesgo que
    poseen los pronóstico.
-   En el ME, los efectos de los errores positivos y negativos se
    cancelan y no hay forma de saber su cantidad exacta.
-   Un ME de cero no significa que los pronósticos sean perfectos o que
    no existan errores de pronóstico, si no que indica que los
    pronósticos no poseen ningún sesgo, y en consecuencia, están
    apuntancia hacia el objetivo correcto.
-   El ME no penaliza los errores extremos de pronóstico.
-   Depende de la escala de medición y también se ve afectada por las
    transformaciones de datos.
-   Para que el pronostico sea bueno, se requiere que el sesgo sea
    mínimo, y por tanto, es deseable que el ME sea lo más cercano a cero
    posible.

<!-- -->

``` r
ME <- function(real, pred) {
    mean(real - pred)
}
```

### Porcentaje medio del error (MPE)

Esta medida está definida como
`\begin{align*} MPE=\frac{1}{m}\sum_{t=T-m+1}^T \frac{e_t}{y_t} \times 100 \end{align*}`

-   Mode el porcentaje de error promedio ocurrido de los pronósticos.
-   Muestra la dirección del error y, en consecuencia, el porcentaje de
    sesgo que poseen los pronóstico.
-   En el MPE, los efectos de los errores positivos y negativos se
    cancelan mutuamente.
-   El MPE es independiente de la escala de medición, pero se ve
    afectado por la transformación de datos.
-   Similar al ME, el obtener valores de MPE cercanos a cero, no indican
    que los pronósticos sean buenos o que no existan errores de
    pronóstico, si no que indica que los pronosticos poseen un sesgo
    pequeño.
-   Similar al ME, es deseable que el sesgo del MPE sea mínimo, es
    decir, que el valor del MPE sea lo más pequeño posible.
-   Al igual que el ME, el MPE no penaliza los errores extremos de
    pronóstico.

<!-- -->

``` r
MPE <- function(real, pred) {
    mean((real - pred)/real) * 100
}
```

### Error absoluto medio (MAE)

Esta medida está definida como
`\begin{align*} MAE=\frac{1}{m}\sum_{t=T-m+1}^T |e_t| \end{align*}`

-   Mide la desviación absoluta promedio de los valores pronosticados
    respecto a los valores reales.
-   También se denomina como la desviación absoluta media (MAD).
-   Muestra la magnitud del error general, ocurrido debido al
    pronóstico.
-   A diferencia del ME, en el MAE, los efectos de los errores positivos
    y negativos no se anulan.
-   A diferencia del ME, el MAE no proporciona ninguna idea sobre el
    sesgo de los pronósticos.
-   Al igual que el ME, el MAE no penaliza los errores extremos de
    pronóstico.
-   Al igual que el ME, el MAE también depende de la escala de medición
    y de las transformaciones de datos.
-   Para que el pronostico sea bueno, se requiere que el MAE obtenido
    sea lo más pequeño posible.

<!-- -->

``` r
MAE <- function(real, pred) {
    mean(abs(real - pred))
}
```

### Porcentaje del error medio absoluto (MAPE)

Esta medida está definida como
`\begin{align*} MAPE=\frac{1}{m}\sum_{t=T-m+1}^T \left|\frac{e_t}{y_t}\right|\times 100 \end{align*}`

-   Mide el porcentaje de error absoluto promedio ocurrido de los
    pronósticos.
-   A diferencia del MPE, el MAPE no proporciona ninguna idea sobre el
    sesgo de los pronósticos.
-   A diferencia del MPE, en el MAPE los efectos de los errores
    positivos y negativos no se anulan.
-   Al igual que el MPE, el MAPE no penaliza los errores extremos de
    pronóstico.
-   Al igual que el MPE, el MAPE también es independiente de la escala
    de medición, pero está afectado por la transformación de datos.

<!-- -->

``` r
MAPE <- function(real, pred) {
    mean(abs((real - pred)/real)) * 100
}
```

### Error cuadrático medio (MSE)

Esta medida está definida como
`\begin{align*} MSE=\frac{1}{m}\sum_{t=T-m+1}^T (e_t)^2 \end{align*}`

-   Mide la desviación al cuadrado promedio de los valores pronosticados
    respecto a los valores reales.
-   En el MSE, los errores positivos y negativos no se compensan entre
    si, y en consecuencia, el MSE proporciona una idea general del error
    ocurrido durante el pronóstico.
-   A diferencia de las otras medidas, el MSE paneliza errores extremos
    ocurridos al pronosticar.
-   El MSE enfatiza el hecho de que el error de pronóstico total está,
    de hecho, muy afectado por grandes errores individuales, es decir,
    los errores grandes son mucho más caros que los errores pequeños.
-   A diferencia del ME y MPE, el MSE no proporciona ninguna idea sobre
    la dirección del error general, es decir, del sesgo de pronóstico.
-   El MSE es sensible al cambio de escala y las transformaciones de
    datos.
-   Aunque el MSE es una buena medida del error de pronóstico general,
    pero NO es tan intuitivo y fácilmente interpretable como las otras
    medidas discutidas anteriormente.

<!-- -->

``` r
MSE <- function(real, pred) {
    mean((real - pred)^2)
}
```

### Suma de cuadrados del error (SSE)

Esta medida está definida como
`\begin{align*} SSE=\sum_{t=T-m+1}^T (e_t)^2 \end{align*}`

-   Posee las mismas propiedades del MSE.

<!-- -->

``` r
SSE <- function(real, pred) {
    sum((real - pred)^2)
}
```

### Raíz cuadrada del error cuadrático medio (RMSE)

Esta medida está definida como
`\begin{align*} RMSE=\sqrt{\frac{1}{m}\sum_{t=T-m+1}^T (e_t)^2} \end{align*}`

-   La RMSE no es más que la raíz cuadrada de la MSE calculada.
-   Todas las demás propiedades de MSE se mantienen para RMSE también.

<!-- -->

``` r
RMSE <- function(real, pred) {
    sqrt(mean((real - pred)^2))
}
```

Función para calcular todas las medidas de error
------------------------------------------------

``` r
Med.error <- function(real, pred) {
    me <- round(mean(real - pred), 4)
    mpe <- round(mean((real - pred)/real) * 100, 4)
    mae <- round(mean(abs(real - pred)), 4)
    mape <- round(mean(abs((real - pred)/real)) * 100, 4)
    mse <- round(mean((real - pred)^2), 4)
    sse <- round(sum((real - pred)^2), 4)
    rmse <- round(sqrt(mean((real - pred)^2)), 4)
    return(data.frame(ME = me, MPE = paste0(mpe, "%"), MAE = mae, MAPE = paste0(mape, 
        "%"), MSE = mse, SSE = sse, RMSE = rmse))
}
```

Bibliografía
------------

Adhikari, R., and Agrawal, R. (2013). An introductory study on time
series modeling and forecasting. *arXiv Preprint arXiv:1302.6613*.
